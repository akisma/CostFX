# CostFX Technical Documentation

*Complete technical reference for the Restaurant Operations AI System*

---

## 📋 Table of Contents

1. [System Overview](#system-overview)
2. [Architecture Reference](#architecture-reference)
3. [Implementation Guides](#implementation-guides)
4. [Technical Solutions](#technical-solutions)
5. [Development Environment](#development-environment)
6. [Deployment Guide](#deployment-guide)
7. [Troubleshooting](#troubleshooting)
8. [Configuration Management](./CONFIGURATION.md) - Centralized configuration system guide

---

## System Overview

### Project Description
CostFX is a multi-agent AI system that automates restaurant operations to reduce human error while maintaining manual override capabilities. The system emphasizes natural language interfaces for recipe management, automated invoice processing, intelligent ordering recommendations, and waste tracking.

### Architecture Components
- **Backend**: Node.js/Express with PostgreSQL
- **Frontend**: React/Vite with Redux Toolkit  
- **AI Agents**: Multi-agent system with specialized capabilities
- **Infrastructure**: AWS ECS with Terraform
- **Containerization**: Docker with separate frontend/backend containers

### Current Implementation Status
- ✅ **Forecast Agent**: Complete with sales, revenue, and labor forecasting (24/24 tests)
- ✅ **Inventory Agent**: Complete with optimization and supplier analysis (21/21 tests)
- ✅ **Cost Agent**: Active with recipe costing and margin analysis
- ✅ **Backend Infrastructure**: Express.js API with agent orchestration
- ✅ **Frontend Dashboard**: React with Redux state management
- ✅ **Database**: PostgreSQL with node-pg-migrate (hierarchical categories with ltree)
- ✅ **Testing**: Complete Vitest-based test suites (151/151 tests passing - 100% success)
- ✅ **Configuration**: Centralized configuration system across entire application
- ✅ **CI/CD**: GitHub Actions with separated app and infrastructure deployments

### Development Status (September 19, 2025)

#### Recently Completed - Dave's Inventory Variance System (Tasks 1-6) ✅
- ✅ **Task 1-2: Hierarchical Categories & Period Management**: PostgreSQL ltree integration with comprehensive period lifecycle
- ✅ **Task 3: Period Inventory Snapshots**: Beginning/ending inventory capture with automatic variance detection
- ✅ **Task 4-5: Enhanced Items & Transactions**: Category integration with variance thresholds and approval workflows
- ✅ **Task 6: Theoretical Usage Analysis Table**: Core variance engine implementing Dave's "saffron vs romaine" principle (37 tests passing)
- ✅ **Task 7: Usage Calculation Service**: Complete variance calculation system with multi-method analysis (40 tests passing)
- ✅ **Task 8: Update Sequelize Models**: Enhanced models with ltree support, proper associations, and Dave's hierarchical category system (14 tests passing)
- ✅ **Database Migration System Modernization**: Migrated from sequelize-cli to node-pg-migrate for ES module compatibility
- ✅ **Migration Testing Framework**: Comprehensive validation suite ensures migration success in development and production
- ✅ **ForecastAgent Production Deployment**: Fixed mixed content security errors preventing HTTPS→HTTP API calls
- ✅ **Frontend Build Configuration**: Corrected GitHub Actions workflow to use proper API URL (`https://www.cost-fx.com/api/v1`)
- ✅ **Backend Environment Variables**: Enhanced database configuration flexibility for production ECS deployment
- ✅ **ECS Task Stability**: Resolved 1486+ failed backend tasks caused by env-var validation conflicts
- ✅ **Database Configuration Robustness**: Made POSTGRES_PASSWORD optional when DATABASE_URL is provided
- ✅ **Production Debugging Methodology**: Systematic investigation using CloudWatch logs, ECS task analysis, and deployment validation

#### Previous Achievements (September 18, 2025)
- ✅ **GitHub Actions OIDC Authentication**: Secure role-based AWS access eliminating access keys
- ✅ **Infrastructure Health Resolution**: Fixed ECS container health checks and environment variables
- ✅ **Container Stability**: All ECS services healthy with proper health check endpoints
- ✅ **Complete Test Suite Overhaul**: Achieved 151/151 tests passing (100% success rate)
- ✅ **InventoryAgent Complete Reconstruction**: Built from scratch with proper capabilities and methods
- ✅ **Configuration Centralization**: Eliminated all hardcoded ports/URLs across codebase
- ✅ **Integration Test Infrastructure**: Fixed route mounting, model mocking, API endpoints
- ✅ **Jest to Vitest Migration**: Resolved ES modules testing issues
- ✅ **GitHub Actions Optimization**: Separated fast app deployment from infrastructure deployment

#### Current Test Health - EXCELLENT ✅ (Verified September 29, 2025)
- **Total Tests**: 399 tests across backend and frontend (VERIFIED)
- **Passing Tests**: 399/399 tests (100% pass rate - CONFIRMED)
- **Backend Tests**: 399/399 passing (comprehensive unit + integration coverage)
- **Frontend Tests**: Frontend tests verified and operational
- **Service Layer Tests**: 28/28 passing for UsageCalculationService (dependency injection)
- **Status**: DEPLOYMENT READY - Fresh Docker deployment successful with all services healthy

#### Latest Achievement - Test Architecture Restoration (September 29, 2025) ✅
- ✅ **Elegant Stateful Mock System**: Successfully restored sophisticated test mock factory in `tests/setup.js`
  - Advanced factory pattern with shared data stores across all test modules
  - Complete CRUD operations with proper state management and type coercion
  - Stateful mocks maintain data consistency throughout test execution
  - Clean separation between test data and business logic validation
- ✅ **Enhanced Model Integration**: Added missing methods to `InventoryPeriod.js` model
  - Implemented `canTransitionTo()` and `getSnapshotCompleteness()` methods
  - Full period lifecycle management with business rule validation
  - Seamless integration between database models and test mocks
- ✅ **Fresh Deployment Validation**: Complete build and deployment verification
  - All 10 database migrations applied successfully (including theoretical usage analysis)
  - Backend API serving correctly on http://localhost:3001
  - Frontend running properly on http://localhost:3000 with correct proxy configuration
  - Database seeded with Demo Restaurant and operational test data
  - Fixed Sequelize auto-sync conflicts by disabling schema alterations in favor of migrations

**Test Categories**:
- ✅ **Core Infrastructure**: Error handling, logging, controllers (100% passing)
- ✅ **ForecastAgent**: Complete implementation (24/24 tests passing)
- ✅ **InventoryAgent**: Complete implementation (21/21 tests passing) 
- ✅ **Dave's Variance System**: Complete business logic implementation (37/37 tests passing)
- ✅ **Integration Tests**: All API endpoints functional (46/46 tests passing)
- ✅ **Frontend Tests**: All components and services tested (49/49 tests passing)

#### System Ready for Production + Local Development Verified
- ✅ **All Core Systems Operational**: Backend, frontend, AI agents, testing, configuration
- ✅ **Local Development Verified**: Fresh Docker Compose deployment with all services healthy
- ✅ **Database Operations**: Migrations completed, seed data loaded (Demo Restaurant created)
- ✅ **API Verification**: All endpoints responding correctly (localhost:3002)
- ✅ **Frontend Verification**: React application serving correctly (localhost:8081)
- ✅ **Service Architecture**: Clean separation between data models and business logic
- ✅ **Secure Authentication**: OIDC-based GitHub Actions with role-based AWS access
- ✅ **Infrastructure Health**: ECS containers healthy with proper environment configuration
- ✅ **Centralized Configuration**: Single source of truth for all ports, URLs, environment settings
- ✅ **Complete Test Coverage**: 100% success rate ensures reliable deployments
- ✅ **Maintainable Architecture**: Clean separation of concerns with dependency injection

---

## Architecture Reference

### High-Level System Architecture
```
Frontend (React Dashboard with Complete Agent Integration)
    ↓
Express.js API Server (Centralized Configuration)
    ↓
Agent Orchestrator (AgentManager + AgentService)
    ↓
┌─────────────────┬─────────────────┬─────────────────┬─────────────────┐
│ Inventory Agent │ Cost Agent      │ Forecast Agent  │ Recipe Agent    │
│  ✅ COMPLETE    │   ✅ ACTIVE     │  ✅ COMPLETE    │  📋 PLANNED     │
│  21/21 tests    │                 │  24/24 tests    │                 │
└─────────────────┴─────────────────┴─────────────────┴─────────────────┘
    ↓
PostgreSQL Database + Redis Cache

Test Coverage: 151/151 tests passing (100% success rate)
Configuration: Centralized across all components
```

### AI Agent System

#### Service Layer Architecture Pattern (Verified September 28, 2025)

**Implementation Status**: ✅ **VERIFIED OPERATIONAL** - Clean separation between data models and business logic

The system implements a clean service layer architecture that separates business logic from data access, enabling better testability, maintainability, and code reuse.

#### **Architecture Components**

**Service Layer** - Contains business logic and calculations
- **UsageCalculationService.js**: Core business logic for inventory variance analysis
  - `calculateActualUsage()`: Inventory movement analysis using snapshot data
  - `calculateVariancePriority()`: Dave's "saffron vs romaine" prioritization logic
  - `buildAnalysisRecord()`: Comprehensive variance analysis data structure
  - Dependency injection design for easy unit testing (28/28 tests passing)

**Agent Layer** - Orchestrates services and manages workflows
- **InventoryVarianceAgent.js**: Business intelligence and workflow management
  - Service coordination through dependency injection
  - No embedded business logic - purely orchestration
  - Result presentation and insight generation
  - Investigation workflow management

**Model Layer** - Pure data structure and database interaction
- **Sequelize Models**: Focus solely on data schema, validation, and relationships
  - No embedded business logic or calculation methods
  - Clean database interaction layer
  - Data integrity and constraint management

#### **Benefits Achieved**

✅ **Testability**: Services can be unit tested independently with mocked dependencies  
✅ **Maintainability**: Clear separation of concerns makes code easier to modify  
✅ **Reusability**: Services can be used across multiple agents and contexts  
✅ **Clean Architecture**: Each layer has a single, well-defined responsibility  
✅ **Dependency Injection**: Enables flexible testing and service composition  

#### BaseAgent Class
**Location**: `backend/src/agents/BaseAgent.js`

Foundation class that all specialized agents inherit from:

```javascript
class BaseAgent {
  constructor(name, capabilities = []) {
    this.name = name;
    this.capabilities = capabilities;
    this.status = 'active';
    this.metrics = {
      requests: 0,
      successRate: 100,
      avgResponseTime: 0
    };
  }

  async process(request) {
    // Abstract method - must be implemented by subclasses
    throw new Error('process method must be implemented by subclass');
  }
}
```

#### Implemented Agents

**CostAgent** (`backend/src/agents/CostAgent.js`)
- Recipe cost calculation and analysis
- Profit margin optimization
- Cost trend monitoring
- Supplier price comparison

**InventoryAgent** (`backend/src/agents/InventoryAgent.js`)
- Inventory level optimization
- Supplier analysis and recommendations
- Stock level alerts
- Purchase order suggestions

**ForecastAgent** (`backend/src/agents/ForecastAgent.js`)
- Demand forecasting with time series analysis
- Seasonal trend analysis
- Revenue prediction with multiple scenarios
- Labor optimization and scheduling

### Database Schema

#### Core Models
- **Restaurant**: Main restaurant entity
- **InventoryItem**: Menu items and ingredients
- **InventoryTransaction**: Stock movements and transactions
- **Supplier**: Vendor information and relationships

#### Key Relationships
- Restaurant → InventoryItems (1:many)
- InventoryItem → InventoryTransactions (1:many)
- Supplier → InventoryItems (many:many)

#### Enhanced Dave's Inventory Management (September 2025)

**New Tables for Variance Analysis:**

**ingredient_categories** - Hierarchical categorization using PostgreSQL ltree
- Supports Dave's requirement: "I don't care if we are off 20 pounds of romaine, but 4oz of saffron is like $600"
- Path examples: `produce.leafy_greens.romaine`, `spices.premium.saffron`
- Enables category-level variance thresholds and alerts

**inventory_periods** - Period-based inventory management
- Support for weekly, monthly, and custom periods
- Lifecycle tracking: draft → active → closed → locked
- Snapshot completion tracking for beginning/ending inventory
- Variance analysis completion status

### POS Integration Architecture

**Status**: ✅ **OAUTH SERVICE COMPLETE** (October 2025) - Full OAuth flow, multi-location support, REST API endpoints

**Implementation**: 
- ✅ Issue #15 - Setup Multi-POS Architecture Foundation
- ✅ Issue #16 - Square OAuth Authentication Service

#### Overview

The POS Integration system provides a secure, READ ONLY, one-way data flow from merchant POS systems (Square, Toast, etc.) into CostFX for analysis. The system never writes data back to merchant POS systems - the merchant's POS remains the authoritative source of truth.

**Data Flow**: POS System → CostFX (READ ONLY)

#### Architecture Components

**1. Provider Adapters** (`backend/src/adapters/`)
- **POSAdapter.js**: Abstract base class defining common interface
- **SquareAdapter.js**: Square POS implementation with OAuth 2.0
- **ToastAdapter.js**: Toast POS stub (future implementation)
- **POSAdapterFactory.js**: Factory pattern for adapter instantiation

**2. Security Services** (`backend/src/services/`)
- **TokenEncryptionService.js**: AES-256-GCM authenticated encryption for OAuth tokens
  - Unique IV per encryption operation
  - Authentication tag for tamper detection
  - Encryption key stored in AWS Secrets Manager (production)
- **OAuthStateService.js**: CSRF protection for OAuth flows
  - Cryptographically secure state tokens
  - 10-minute TTL for attack window limitation
  - One-time use tokens (prevents replay attacks)

**3. Data Models** (`backend/src/models/`)
- **POSConnection.js**: OAuth connection management with encrypted token storage
  - Unique constraint: one connection per (restaurant_id, provider)
  - Token expiration tracking and refresh
  - Connection status lifecycle (active, expired, revoked, error)

**4. Error Handling** (`backend/src/utils/`)
- **posErrors.js**: Specialized error classes
  - POSAuthError: OAuth and authentication failures
  - POSTokenError: Token encryption/refresh failures
  - POSSyncError: Data synchronization failures
  - POSConfigError: Configuration validation failures
  - POSRateLimitError: API rate limiting

#### Database Schema

**pos_connections** table:
```sql
CREATE TABLE pos_connections (
  id SERIAL PRIMARY KEY,
  restaurant_id INTEGER NOT NULL REFERENCES restaurants(id) ON DELETE CASCADE,
  provider VARCHAR(50) NOT NULL,  -- 'square', 'toast', etc.
  merchant_id VARCHAR(255) NOT NULL,  -- POS merchant identifier
  location_id VARCHAR(255),  -- POS location identifier
  access_token_encrypted TEXT,  -- AES-256-GCM encrypted
  access_token_iv VARCHAR(32),  -- Initialization vector
  refresh_token_encrypted TEXT,  -- AES-256-GCM encrypted
  refresh_token_iv VARCHAR(32),  -- Initialization vector
  token_expires_at TIMESTAMP WITH TIME ZONE,
  status VARCHAR(50) DEFAULT 'active',  -- active, expired, revoked, error
  last_sync_at TIMESTAMP WITH TIME ZONE,
  metadata JSONB,  -- Provider-specific data
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  UNIQUE(restaurant_id, provider)  -- One connection per provider per restaurant
);
```

**Indexes:**
- `idx_pos_provider`: Fast provider lookups
- `idx_pos_restaurant`: Restaurant's connections
- `idx_pos_status`: Active connection queries
- `idx_pos_sync`: Last sync timestamp queries

#### Square Integration

**Two-Tier Data Architecture (October 11, 2025):**

The Square integration implements a two-tier data architecture that separates raw POS data from normalized inventory:

**Tier 1: Raw POS Data (POS-Specific Tables)**
- `square_categories`: Catalog categories from Square
- `square_menu_items`: Menu items with Square-specific fields
- Purpose: Preserve original POS data for debugging and re-transformation
- Updated via: `SquareAdapter.syncInventory()` with cursor pagination

**Tier 2: Normalized Inventory (Unified Schema)**
- `inventory_items`: CostFX normalized inventory format
- Purpose: Unified format for analysis across all POS providers
- Updated via: `POSDataTransformer.transformBatch()`
- Includes: Dave's variance threshold fields, category mapping, unit normalization

**Data Flow:**
```
Square API → SquareAdapter (Tier 1 sync) → square_* tables
square_* tables → POSDataTransformer → inventory_items (Tier 2)
```

**Key Features:**
- **Idempotent**: Upsert based on `(restaurant_id, source_pos_provider, source_pos_item_id)`
- **Separated Operations**: Import and transform are independent
- **Graceful Degradation**: Category mapping falls back to 'dry_goods'
- **Unit Normalization**: Maps Square units to CostFX validation (lb→lbs, ea→pieces)
- **Variance Thresholds**: Populates Dave's high-value tracking fields

**OAuth 2.0 Flow:**
1. **Initiate**: Generate state token, redirect to Square authorization
2. **Callback**: Verify state, exchange code for tokens
3. **Store**: Encrypt and save access/refresh tokens
4. **Refresh**: Automatic token refresh before expiration (30-day tokens)
5. **Revoke**: Clean disconnect with token revocation

**OAuth Scopes (READ ONLY):**
- `ITEMS_READ`: Catalog/inventory items (NO WRITE ACCESS)
- `INVENTORY_READ`: Stock counts (NO WRITE ACCESS)
- `ORDERS_READ`: Sales/order data (NO WRITE ACCESS)
- `MERCHANT_PROFILE_READ`: Business information

**Square SDK**: `square` npm package v37.1.0

**Webhook Support:**
- HMAC-SHA256 signature verification
- Event types: inventory updates, catalog changes, order events
- Signature header: `x-square-hmacsha256-signature`

#### Security Best Practices

✅ **Token Encryption**: AES-256-GCM with unique IVs  
✅ **CSRF Protection**: State tokens for OAuth flows  
✅ **No Sensitive Logging**: Tokens never logged  
✅ **READ ONLY Scopes**: No write permissions requested  
✅ **Token Rotation**: Refresh tokens properly rotated  
✅ **Webhook Verification**: Cryptographic signature validation  

#### Environment Configuration

Required environment variables (see `.env.example`):

```bash
# Token Encryption (CRITICAL - use secure key in production)
TOKEN_ENCRYPTION_KEY=<32-byte-hex-key>  # Generate with: openssl rand -hex 32

# Square POS Configuration
SQUARE_OAUTH_CLIENT_ID=<from Square Developer Dashboard>
SQUARE_OAUTH_CLIENT_SECRET=<from Square Developer Dashboard>
SQUARE_OAUTH_REDIRECT_URI=https://your-domain.com/api/pos/square/callback
SQUARE_ENVIRONMENT=sandbox  # or 'production'
SQUARE_WEBHOOK_SIGNATURE_KEY=<from Square Developer Dashboard>
SQUARE_WEBHOOKS_ENABLED=true

# Toast POS Configuration (Future)
TOAST_CLIENT_ID=<future>
TOAST_CLIENT_SECRET=<future>
TOAST_OAUTH_REDIRECT_URI=https://your-domain.com/api/pos/toast/callback
```

#### Usage Example

```javascript
// Initialize factory
await POSAdapterFactory.initialize();

// Get adapter for provider
const adapter = await POSAdapterFactory.getAdapter('square');

// Initiate OAuth flow
const { authorizationUrl, state } = await adapter.initiateOAuth(restaurantId);
// Redirect user to authorizationUrl...

// Handle OAuth callback
const connection = await adapter.handleOAuthCallback({
  code: req.query.code,
  state: req.query.state,
  restaurantId
});

// Sync inventory (READ ONLY from Square)
const result = await adapter.syncInventory(connection);
console.log(`Synced ${result.synced} items`);

// Health check
const health = await adapter.healthCheck(connection);
console.log(`Connection healthy: ${health.healthy}`);
```

#### Square OAuth Authentication Service

**Status**: ✅ **COMPLETE** (October 4, 2025) - Issue #16

**Implementation Files:**

**Database:**
- `migrations/1759612780000_create-square-locations.js` - Multi-location support table
- `models/SquareLocation.js` - Location model with sync tracking and helper methods
- `models/POSConnection.js` - Updated with SquareLocation association

**Middleware:**
- `middleware/restaurantContext.js` - Restaurant-centric authentication (no User model)
  - `requireRestaurant`: Extract restaurantId from request (defaults to 1 in dev)
  - `optionalRestaurant`: Non-failing version for optional auth
  - `validateRestaurantAccess`: Placeholder for future User integration
- `middleware/squareAuthMiddleware.js` - Square-specific validation
  - `requireSquareConnection`: Validate active connection, check token expiry
  - `validateOAuthCallback`: OAuth callback parameter validation
  - `squareErrorHandler`: Convert POS errors to HTTP responses
  - `squareOAuthRateLimit`: Rate limiter (10 requests/15min)

**Service Layer:**
- `services/SquareAuthService.js` - Business logic orchestration
  - `initiateConnection()`: Start OAuth flow with state token
  - `handleCallback()`: Exchange authorization code for tokens
  - `getConnectionStatus()`: Check connection and location status
  - `getLocations()`: Fetch available Square locations
  - `selectLocations()`: Save selected locations for sync
  - `disconnect()`: Revoke OAuth tokens and disconnect
  - `healthCheck()`: Verify connection operational status

**Controller Layer:**
- `controllers/SquareAuthController.js` - HTTP request handlers
  - 7 controller methods with error handling and response formatting

**Routes:**
- `routes/squareAuth.js` - Express routes with Swagger documentation
  - `POST /api/v1/pos/square/connect` - Initiate OAuth
  - `GET /api/v1/pos/square/callback` - Handle OAuth callback
  - `GET /api/v1/pos/square/status` - Get connection status
  - `GET /api/v1/pos/square/locations` - List available locations
  - `POST /api/v1/pos/square/locations/select` - Select locations for sync
  - `POST /api/v1/pos/square/disconnect` - Disconnect integration
  - `GET /api/v1/pos/square/health` - Health check endpoint

**Database Schema - square_locations:**
```sql
CREATE TABLE square_locations (
  id SERIAL PRIMARY KEY,
  pos_connection_id INTEGER NOT NULL REFERENCES pos_connections(id) ON DELETE CASCADE,
  location_id VARCHAR(255) NOT NULL,  -- Square location ID
  location_name VARCHAR(255) NOT NULL,
  address JSONB,  -- Full address object from Square
  status VARCHAR(50) DEFAULT 'active',
  capabilities JSONB,  -- Location capabilities array
  sync_enabled BOOLEAN DEFAULT true,
  last_sync_at TIMESTAMP WITH TIME ZONE,
  metadata JSONB,  -- Additional location metadata
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  UNIQUE(pos_connection_id, location_id)
);
```

**Indexes:**
- `idx_square_locations_connection`: Fast connection lookups
- `idx_square_locations_location_id`: Square location ID queries
- `idx_square_locations_sync`: Sync status queries
- `idx_square_locations_status`: Status filtering

**Architecture Decisions:**

1. **Restaurant-Centric (No User Model)**: 
   - Deferred User model to Issue #26+ (post-MVP)
   - Middleware defaults to restaurantId=1 in development
   - 100+ line comment documents rationale and future User integration path
   - Simplifies MVP while maintaining future extensibility

2. **Multi-Location Support**:
   - Restaurants can select multiple Square locations
   - Each location tracked separately for sync operations
   - Location-specific metadata and capabilities storage

3. **Comprehensive Error Handling**:
   - Custom error classes for POS-specific failures
   - Middleware converts errors to appropriate HTTP responses
   - Rate limiting prevents OAuth abuse

4. **API Documentation**:
   - Full Swagger/OpenAPI 3.0 documentation
   - Accessible at `/api-docs` endpoint
   - Request/response schemas for all endpoints

**Testing:**
- ✅ All 399 tests passing (100% success rate)
- ✅ POSAdapterFactory mock added to test setup
- ✅ Model associations tested and operational
- ✅ Dev server starts without errors

**Validation:**
- ✅ Migration applied successfully to database
- ✅ All routes registered at `/api/v1/pos/square`
- ✅ Swagger documentation generated
- ✅ No linting or syntax errors
- ✅ Integration with existing POSAdapterFactory

#### Square Adapter Implementation

**Status**: ✅ **COMPLETE** (October 5, 2025) - Issue #19

**Implementation**: Full Square POS adapter with syncInventory(), healthCheck(), rate limiting, and retry policy. Comprehensive integration testing validates end-to-end data flows from Square API through adapter to database storage.

**Test Coverage**: 514/514 tests passing (100% pass rate)
- ✅ 14/14 core integration tests passing (100%)
- ✅ 33/33 SquareAdapter unit tests passing (100%)
- ✅ 43/43 rate limiter & retry policy tests passing (100%)
- ✅ End-to-end validation from OAuth → Sync → Database

**Implementation Files:**

**Core Adapter:**
- `backend/src/adapters/SquareAdapter.js` (1274 lines)
  - Complete implementation extending POSAdapter base class
  - syncInventory() with 5 helper methods (240+ lines)
  - healthCheck() using merchant API
  - Rate limiting and retry policy integration

**Utility Services:**
- `backend/src/utils/SquareRateLimiter.js` (290 lines)
  - Token bucket algorithm for rate limiting
  - Per-connection tracking (80 requests per 10 seconds)
  - Statistics collection and monitoring
- `backend/src/utils/SquareRetryPolicy.js` (278 lines)
  - Exponential backoff (1-30 seconds)
  - Retryable status codes: 429, 500, 502, 503, 504
  - Comprehensive retry statistics

**Test Files:**
- `backend/tests/unit/SquareAdapter.test.js` (670+ lines, 33 tests) ✅
- `backend/tests/unit/SquareRateLimiter.test.js` (22 tests) ✅
- `backend/tests/unit/SquareRetryPolicy.test.js` (21 tests) ✅
- `backend/tests/integration/squareAdapterCore.test.js` (278 lines, 14 tests) ✅
- `backend/tests/fixtures/squareApiResponses.js` (430+ lines mock data)

**Key Features:**

**1. syncInventory() - Complete Inventory Synchronization**

Syncs catalog items, categories, and inventory counts from Square to CostFX database.

```javascript
/**
 * Sync inventory data from Square to local database
 * @param {POSConnection} connection - Active Square connection
 * @param {Object} options - Sync options
 * @param {Date} options.since - Only sync items modified after this date
 * @returns {Promise<Object>} Sync results with counts and errors
 */
async syncInventory(connection, options = {}) {
  // Returns: { synced, errors, details: { categories, items, inventoryCounts } }
}
```

**Implementation Details:**
- **Cursor Pagination**: Handles large catalogs with automatic pagination
- **Incremental Sync**: Uses `options.since` timestamp for efficient updates
- **Batch Processing**: Inventory counts processed in batches of 100 IDs
- **Error Collection**: Collects errors without failing entire sync
- **Rate Limiting**: Respects Square API limits (80 req/10s per connection)
- **Retry Policy**: Automatically retries transient failures

**Helper Methods:**
- `_syncCatalogObjects()`: Fetch and process catalog items with pagination
- `_storeCatalogCategory()`: Upsert category with conflict handling
- `_storeCatalogItem()`: Upsert menu item with variation tracking
- `_syncInventoryCounts()`: Batch inventory count retrieval
- `_storeInventoryCount()`: Store historical inventory snapshots

**Usage Example:**
```javascript
const adapter = new SquareAdapter();
const connection = await POSConnection.findOne({ 
  where: { restaurantId, provider: 'square' } 
});

// Full sync
const result = await adapter.syncInventory(connection);
console.log(`Synced ${result.details.categories} categories`);
console.log(`Synced ${result.details.items} menu items`);
console.log(`Synced ${result.details.inventoryCounts} inventory counts`);

// Incremental sync (only changes since last sync)
const incrementalResult = await adapter.syncInventory(connection, {
  since: connection.lastSyncAt
});
```

**2. healthCheck() - Connection Health Verification**

Verifies Square connection is operational by calling merchant API.

```javascript
/**
 * Check if the Square connection is healthy
 * @param {POSConnection} connection - Connection to verify
 * @returns {Promise<Object>} Health status with details
 */
async healthCheck(connection) {
  // Returns: { healthy, message, details: { merchant, tokenExpiry } }
}
```

**Health Check Process:**
1. Verify connection is active and not expired
2. Call Square merchant API to validate credentials
3. Check token expiration (warn if < 24 hours)
4. Return detailed health status

**Usage Example:**
```javascript
const health = await adapter.healthCheck(connection);

if (health.healthy) {
  console.log('Connection operational');
  console.log(`Merchant: ${health.details.merchant.businessName}`);
  console.log(`Token expires in: ${health.details.tokenExpiry.hoursRemaining}h`);
} else {
  console.error(`Health check failed: ${health.message}`);
  // Handle token refresh or reconnection
}
```

**3. Rate Limiting Strategy**

**Token Bucket Algorithm:**
- **Capacity**: 80 requests per connection
- **Refill Rate**: 80 tokens every 10 seconds
- **Per-Connection**: Separate bucket for each Square connection
- **Graceful Handling**: Waits for token availability

**Implementation:**
```javascript
const rateLimiter = new SquareRateLimiter();

// Rate limiter automatically applied in API calls
await rateLimiter.acquireToken(connectionId);
// Make Square API call
```

**Statistics Tracking:**
```javascript
const stats = rateLimiter.getStats(connectionId);
console.log(`Requests made: ${stats.requestCount}`);
console.log(`Tokens available: ${stats.tokensAvailable}`);
console.log(`Wait time: ${stats.averageWaitTime}ms`);
```

**4. Retry Policy Strategy**

**Exponential Backoff:**
- **Initial Delay**: 1 second
- **Max Delay**: 30 seconds
- **Max Attempts**: 3 retries
- **Backoff Factor**: 2x (1s → 2s → 4s)
- **Jitter**: ±25% randomization to prevent thundering herd

**Retryable Errors:**
- `429` - Rate Limit Exceeded
- `500` - Internal Server Error
- `502` - Bad Gateway
- `503` - Service Unavailable
- `504` - Gateway Timeout

**Non-Retryable Errors:**
- `400` - Bad Request (client error)
- `401` - Unauthorized (invalid credentials)
- `403` - Forbidden (insufficient permissions)
- `404` - Not Found (resource doesn't exist)

**Usage Example:**
```javascript
const retryPolicy = new SquareRetryPolicy();

const result = await retryPolicy.execute(async () => {
  // Square API call that might fail transiently
  return await squareClient.catalogApi.listCatalog();
});

const stats = retryPolicy.getStats();
console.log(`Total attempts: ${stats.totalAttempts}`);
console.log(`Successful retries: ${stats.successfulRetries}`);
console.log(`Failed after retries: ${stats.failedAfterRetries}`);
```

**5. Data Flow Architecture**

**Square API → Adapter → Database:**

```
┌─────────────────┐
│   Square API    │
│ (Catalog API)   │
│ (Inventory API) │
│ (Merchant API)  │
└────────┬────────┘
         │
         │ OAuth Token
         │ Rate Limited (80/10s)
         │ Retry on Failure
         │
         ▼
┌─────────────────┐
│ SquareAdapter   │
│  syncInventory()│
│  healthCheck()  │
└────────┬────────┘
         │
         │ Processed Data
         │ Error Collection
         │
         ▼
┌─────────────────┐
│  Database       │
│ - square_       │
│   categories    │
│ - square_menu_  │
│   items         │
│ - square_       │
│   inventory_    │
│   counts        │
└─────────────────┘
```

**6. Integration Testing**

**Core Integration Tests** (`squareAdapterCore.test.js`):

1. **Core Sync Functionality** (5 tests)
   - Complete sync operation from API to database
   - Square API calls during sync (catalog + inventory)
   - Database upserts for categories and items
   - Incremental sync with timestamp filtering
   - lastSyncAt timestamp updates

2. **Rate Limiting** (2 tests)
   - Rate limiter usage during sync operations
   - Request statistics tracking

3. **Retry Policy** (2 tests)
   - Retry on transient failures (503 errors)
   - No retry on non-retryable errors (400)

4. **Health Check** (3 tests)
   - Verify healthy connection status
   - Detect inactive connections
   - Merchant API call verification

5. **Error Handling** (2 tests)
   - Error collection without failing entire sync
   - Graceful API error handling

**Test Execution:**
```bash
# Run all SquareAdapter tests
npm test -- SquareAdapter

# Run integration tests
npm test -- integration/squareAdapterCore

# Run rate limiter tests
npm test -- SquareRateLimiter

# Run retry policy tests
npm test -- SquareRetryPolicy
```

**7. Production Considerations**

**Best Practices:**
- Always check connection health before sync operations
- Use incremental sync with `since` parameter for efficiency
- Monitor rate limiter statistics for capacity planning
- Review retry statistics to identify persistent issues
- Handle sync errors gracefully without blocking operations
- Schedule syncs during off-peak hours when possible
- Implement monitoring for sync failures and token expiration

**Error Handling:**
```javascript
try {
  const result = await adapter.syncInventory(connection);
  
  if (result.errors.length > 0) {
    console.warn(`Sync completed with ${result.errors.length} errors`);
    result.errors.forEach(err => {
      console.error(`Error: ${err.message}`);
    });
  }
  
  // Update sync timestamp
  connection.lastSyncAt = new Date();
  await connection.save();
} catch (error) {
  console.error('Sync failed:', error);
  // Implement retry logic or alert monitoring
}
```

**Performance Metrics:**
- Average sync time: ~2-5 seconds for 100 items
- Rate limiting overhead: <100ms per request
- Retry overhead: 1-8 seconds for transient failures
- Database upsert: <10ms per item

**Known Limitations:**
- Square API rate limits: 80 requests per 10 seconds per location
- Inventory batch size: 100 item IDs per request
- Token expiration: Must refresh before 30 days
- Pagination cursor: Valid for limited time window

#### Future Enhancements

📋 **Planned:**
- ✅ Complete syncInventory() implementation (Square Catalog API) - **COMPLETE** (Issue #19)
- Complete syncSales() implementation (Square Orders API)
- Toast POS adapter implementation
- Webhook processing for real-time updates
- Scheduled sync jobs (daily/hourly)
- Sync conflict resolution strategies
- User model integration for multi-user support (Issue #26+)

For detailed integration guide, see [POS_INTEGRATION_GUIDE.md](./POS_INTEGRATION_GUIDE.md)

### Database Migration System

**Migration Tool**: node-pg-migrate (ES module compatible, PostgreSQL-optimized)

#### Running Migrations

**Local Development:**
```bash
# Apply all pending migrations
npm run migrate:up

# Roll back last migration
npm run migrate:down 1

# Create new migration
npm run migrate:create migration-name
```

**Production Deployment:**
- Migrations run automatically during GitHub Actions deployment
- ECS task execution: `npm run migrate:up`
- Deploy script: `./deploy.sh --migrate-only`

#### Testing Migration Success

**Quick Validation:**
```bash
# Comprehensive test suite (RECOMMENDED)
npm run migrate:test

# Or run manually
./backend/scripts/test-migrations.sh
```

**Manual Verification:**
```bash
# Check migration tracking
docker-compose exec -T db psql -U postgres -d restaurant_ai -c \
  "SELECT name, run_on FROM pgmigrations ORDER BY run_on;"

# Verify hierarchical categories
docker-compose exec -T db psql -U postgres -d restaurant_ai -c \
  "SELECT name, path FROM ingredient_categories WHERE path <@ 'produce';"

# Test ltree functionality  
docker-compose exec -T db psql -U postgres -d restaurant_ai -c \
  "SELECT COUNT(*) FROM ingredient_categories WHERE path ~ '*.saffron';"

# Check inventory periods
docker-compose exec -T db psql -U postgres -d restaurant_ai -c \
  "SELECT period_name, status, period_type FROM inventory_periods;"
```

**What the Tests Validate:**
- ✅ **Migration Tracking**: 5 migrations in `pgmigrations` table (suppliers, inventory-items, inventory-transactions, ingredient-categories, inventory-periods)
- ✅ **Table Structure**: Core tables (suppliers, inventory_items, inventory_transactions) and Dave's enhancements (ingredient_categories, inventory_periods)
- ✅ **ltree Extension**: PostgreSQL ltree enabled for hierarchical queries
- ✅ **Hierarchical Data**: 6 ingredient categories with proper hierarchy
- ✅ **Period Management**: 3 inventory periods (2 weekly, 1 monthly)
- ✅ **Dave's Use Cases**: Romaine (low-value) vs Saffron (high-value) hierarchy ready
- ✅ **Indexes & Constraints**: Performance optimizations and data integrity

**Production Testing:**
- GitHub Actions automatically runs migrations during deployment
- Health checks verify application startup after migration
- Rollback capability available via `npm run migrate:down`

**Migration Success Indicators:**
- All tests pass in `npm run migrate:test`
- Database contains expected tables and data
- ltree extension enabled for hierarchical queries
- Application starts successfully after migration

### API Structure

#### Agent Endpoints
- `GET /api/v1/agents/status` - Agent system status
- `POST /api/v1/agents/cost/analyze` - Cost analysis
- `POST /api/v1/agents/inventory/optimize` - Inventory optimization
- `POST /api/v1/agents/forecast/demand` - Demand forecasting
- `POST /api/v1/agents/forecast/revenue` - Revenue prediction

#### Resource Endpoints
- `/api/v1/restaurants` - Restaurant management
- `/api/v1/inventory` - Inventory operations
- `/api/v1/ingredients` - Ingredient catalog
- `/api/v1/recipes` - Recipe management

### Dave's Inventory Variance Management System

**Implementation Status**: ✅ **Tasks 1-6 Complete** (September 2025)

Dave's core business requirement: *"I don't care if we are off 20 pounds of romaine, but 4oz of saffron is like $600"*

This system implements a comprehensive variance analysis framework that prioritizes high-value inventory discrepancies while ignoring acceptable variances in low-value bulk items.

#### Task Implementation Summary

**✅ Task 1: Hierarchical Ingredient Categories**
- **Migration**: `1726790000001_create-ingredient-categories.js`
- **Features**: PostgreSQL ltree extension for hierarchical paths
- **Structure**: `produce.leafy_greens.romaine` vs `spices.premium.saffron`
- **Business Logic**: Category-level variance thresholds and priority classification

**✅ Task 2: Inventory Period Management**
- **Migration**: `1726790000003_create-inventory-periods.js`
- **Features**: Weekly/monthly periods with lifecycle tracking
- **States**: draft → active → closed → locked
- **Integration**: Foundation for variance analysis workflows

**✅ Task 3: Period Inventory Snapshots**
- **Migration**: `1726790000005_create-period-inventory-snapshots.js`
- **Features**: Beginning/ending inventory capture per period
- **Calculations**: Automatic variance detection and delta analysis
- **Validation**: Ensures data integrity for variance calculations

**✅ Task 4: Enhanced Inventory Items**
- **Migration**: `1726790000007_update-inventory-items-categories.js`
- **Features**: Category integration with variance thresholds
- **Dave's Logic**: High-value flags, theoretical yield factors
- **Thresholds**: Quantity, percentage, and dollar-based variance limits

**✅ Task 5: Enhanced Inventory Transactions**
- **Migration**: `1726790000006_enhance-inventory-transactions.js`
- **Features**: Variance tracking with approval workflows
- **Categories**: waste, theft, measurement_error, spoilage, transfer
- **Workflow**: Automatic approval routing for significant variances

**✅ Task 6: Theoretical Usage Analysis Table**
- **Migration**: `1726790000008_create-theoretical-usage-analysis.js`
- **Model**: `TheoreticalUsageAnalysis.js` with comprehensive business logic
- **Features**: Core variance engine implementing Dave's priority system
- **Tests**: 37 passing tests covering all business scenarios

#### Core Database Schema

**theoretical_usage_analysis** - Central variance analysis engine
```sql
CREATE TABLE theoretical_usage_analysis (
  id SERIAL PRIMARY KEY,
  period_id INTEGER REFERENCES inventory_periods(id),
  inventory_item_id INTEGER REFERENCES inventory_items(id),
  
  -- Usage calculations
  theoretical_quantity DECIMAL(10,2) NOT NULL,
  actual_quantity DECIMAL(10,2) NOT NULL,
  unit_cost DECIMAL(10,2) NOT NULL,
  
  -- Dave's variance metrics
  variance_quantity DECIMAL(10,2) NOT NULL,
  variance_percentage DECIMAL(8,4),
  variance_dollar_value DECIMAL(10,2) NOT NULL,
  
  -- Priority system
  priority VARCHAR(10) CHECK (priority IN ('critical','high','medium','low')),
  is_significant BOOLEAN DEFAULT FALSE,
  requires_investigation BOOLEAN DEFAULT FALSE,
  
  -- Investigation workflow
  investigation_status VARCHAR(15) DEFAULT 'pending'
    CHECK (investigation_status IN ('pending','investigating','resolved','accepted','escalated')),
  assigned_to INTEGER REFERENCES users(id),
  investigated_by INTEGER REFERENCES users(id),
  explanation TEXT,
  investigation_notes TEXT,
  
  -- Calculation metadata
  calculation_method VARCHAR(20) DEFAULT 'recipe_based'
    CHECK (calculation_method IN ('recipe_based','historical_average','manual','ai_predicted')),
  recipe_data JSONB,
  calculation_confidence DECIMAL(3,2) CHECK (calculation_confidence BETWEEN 0.0 AND 1.0)
);
```

#### Business Logic Implementation

**Dave's Priority Classification:**
```javascript
// High-impact variance identification
isHighImpactVariance() {
  const absVariance = Math.abs(this.varianceDollarValue || 0);
  return absVariance >= 100 || this.priority === 'critical' || this.priority === 'high';
}

// Saffron vs Romaine principle
getAbsoluteVariance() {
  return {
    quantity: Math.abs(this.varianceQuantity || 0),
    dollarValue: Math.abs(this.varianceDollarValue || 0),
    percentage: Math.abs(this.variancePercentage || 0)
  };
}
```

**Investigation Workflow:**
```javascript
// Assignment workflow
async assignInvestigation(userId, notes = null) {
  await this.update({
    assignedTo: userId,
    investigationStatus: 'investigating',
    assignedAt: new Date(),
    investigationNotes: notes
  });
}

// Resolution workflow
async resolveInvestigation(userId, explanation, resolution = 'resolved') {
  await this.update({
    investigatedBy: userId,
    investigationStatus: resolution,
    resolvedAt: new Date(),
    explanation: explanation
  });
}
```

**Management Queries:**
```javascript
// Find Dave's high priority variances
static async findHighPriorityVariances(periodId) {
  return this.findAll({
    where: { priority: { [Op.in]: ['critical', 'high'] } },
    order: [
      ['priority', 'DESC'],
      [sequelize.fn('ABS', sequelize.col('variance_dollar_value')), 'DESC']
    ]
  });
}

// Dollar threshold filtering
static async findByDollarThreshold(threshold = 100) {
  return this.findAll({
    where: {
      [Op.or]: [
        { varianceDollarValue: { [Op.gte]: threshold } },
        { varianceDollarValue: { [Op.lte]: -threshold } }
      ]
    }
  });
}
```

#### Dave's Business Scenarios

**Saffron Scenario (High Priority)**
- **Variance**: 0.25 oz overage ($37.50 impact)
- **Classification**: High priority due to expensive ingredient
- **Action**: Requires investigation despite small quantity
- **Dave's Response**: ✅ "This needs attention - saffron is expensive"

**Romaine Scenario (Low Priority)**
- **Variance**: 20 lbs overage ($50.00 impact)
- **Classification**: Low priority despite large quantity
- **Action**: No investigation required
- **Dave's Response**: ✅ "Don't care - it's just lettuce"

#### Performance Optimizations

**Strategic Indexes:**
```sql
-- Dave's primary queries
CREATE INDEX idx_variance_priority ON theoretical_usage_analysis(priority);
CREATE INDEX idx_variance_dollar ON theoretical_usage_analysis(variance_dollar_value);
CREATE INDEX idx_investigation_status ON theoretical_usage_analysis(investigation_status);

-- Composite indexes for management reports
CREATE INDEX idx_period_priority ON theoretical_usage_analysis(period_id, priority);
CREATE INDEX idx_period_significant ON theoretical_usage_analysis(period_id, is_significant);
CREATE INDEX idx_assigned_status ON theoretical_usage_analysis(assigned_to, investigation_status);
```

#### Testing Coverage

**Comprehensive Test Suite** (`TheoreticalUsageAnalysisCorrected.test.js`)
- **37 passing tests** covering all business logic
- **Dave's scenarios**: Saffron, romaine, truffle, flour examples
- **Investigation workflow**: Assignment, resolution, escalation
- **Edge cases**: Zero quantities, negative variances, invalid data
- **Display formatting**: Currency, percentages, investigation status

**Key Test Categories:**
```javascript
describe('Dave\'s Core Business Logic', () => {
  // getAbsoluteVariance(), isHighImpactVariance(), getVarianceDirection()
});

describe('Investigation Workflow', () => {
  // assignInvestigation(), resolveInvestigation(), canBeResolved()
});

describe('Dave\'s Business Scenarios', () => {
  // Saffron vs romaine principle validation
});
```

#### Integration Architecture

**Data Flow:**
1. **Period Creation** → inventory_periods table
2. **Snapshot Capture** → period_inventory_snapshots table  
3. **Usage Calculation** → theoretical_usage_analysis table (Task 6)
4. **Investigation Workflow** → status updates in theoretical_usage_analysis
5. **Management Reporting** → aggregated queries from theoretical_usage_analysis

**Next Phase Integration** (Tasks 7-10):
- **Task 7**: Usage calculation service populates analysis table
- **Task 8**: Investigation API manages workflow transitions
- **Task 9**: Dashboard queries analysis table for management reports
- **Task 10**: Alert system monitors for critical variances

**Production Ready Features:**
- ✅ Complete database schema with constraints and indexes
- ✅ Comprehensive business logic models with Sequelize
- ✅ Full test coverage ensuring reliability
- ✅ Performance optimized for Dave's management queries
- ✅ Investigation workflow supporting team collaboration
- ✅ Flexible calculation methods (recipe-based, historical, AI)

**✅ Task 7: Usage Calculation Service**
- **Service**: `UsageCalculationService.js` (600+ lines) - Complete variance calculation engine
- **Agent**: `InventoryVarianceAgent.js` (400+ lines) - Business intelligence and workflow management
- **Features**: Multi-method calculation system populating theoretical_usage_analysis table
- **Tests**: 40 passing tests (23 service + 17 agent) validating all business scenarios

#### Core Service Architecture

**Usage Calculation Service** - Dave's variance calculation engine
```javascript
class UsageCalculationService {
  // Main entry point for period analysis
  async calculateUsageForPeriod(periodId, options = {}) {
    // 1. Get inventory items and period data
    // 2. Calculate theoretical usage (multiple methods)
    // 3. Calculate actual usage from inventory movement
    // 4. Apply Dave's priority classification
    // 5. Populate theoretical_usage_analysis table
  }
  
  // Multiple calculation methods
  calculateRecipeBasedUsage(item, period)      // Recipe × sales data
  calculateHistoricalAverageUsage(item, period) // Past usage patterns  
  calculateActualUsage(item, period)           // Inventory movement analysis
  calculateVariancePriority(item, absQty, absDollar) // Dave's business rules
}
```

**Calculation Methods:**

1. **Recipe-Based** (Primary Method)
   ```javascript
   // Formula: sum(recipe_quantity × sales_quantity × yield_factor)
   const baseQuantity = recipesUsed.reduce(
     (total, recipe) => total + (recipe.quantityPerServing * recipe.soldQuantity), 0
   );
   const adjustedQuantity = baseQuantity / item.theoreticalYieldFactor;
   ```

2. **Historical Average** (Fallback Method)
   ```javascript
   // Analyzes past 6 periods for usage patterns
   const averageUsage = historicalAnalyses.reduce(
     (sum, analysis) => sum + parseFloat(analysis.actualQuantity), 0
   ) / historicalAnalyses.length;
   ```

3. **Actual Usage** (Inventory Movement)
   ```javascript
   // Formula: beginning_quantity + purchases - ending_quantity = actual_usage
   const actualUsage = beginningQuantity + totalPurchases - endingQuantity;
   ```

#### Agent Integration

**InventoryVarianceAgent** - Business intelligence and workflow management
```javascript
class InventoryVarianceAgent extends BaseAgent {
  capabilities = [
    'calculate_usage_variance',    // Period-based calculation
    'analyze_period_variance',     // Pattern analysis  
    'priority_variance_summary',   // Management dashboard
    'historical_variance_trends',  // Multi-period analysis
    'investigate_variance',        // Workflow initiation
    'resolve_variance_investigation' // Workflow completion
  ];
}
```

**Business Intelligence Features:**
```javascript
// Generate actionable insights
generateVarianceInsights(result) {
  // High-priority alerts for critical variances
  // Financial impact warnings for large dollar variances  
  // Confidence warnings for data quality issues
}

// Recommend process improvements
generateVarianceRecommendations(summary) {
  // Critical investigation assignments
  // Data quality improvements (recipe coverage)
  // Calculation accuracy enhancements
}
```

#### Dave's Priority System Implementation

**Variance Priority Classification:**
```javascript
calculateVariancePriority(item, absQuantityVariance, absDollarVariance) {
  const quantityThreshold = item.varianceThresholdQuantity || 5.0;
  const dollarThreshold = item.varianceThresholdDollar || 25.0;
  
  // Critical: High-value items or large dollar impact
  if (item.highValueFlag || absDollarVariance >= dollarThreshold * 2) {
    return 'critical';
  }
  
  // High: Exceeds both quantity and dollar thresholds
  if (absQuantityVariance >= quantityThreshold && absDollarVariance >= dollarThreshold) {
    return 'high';
  }
  
  // Medium: Exceeds one threshold significantly  
  if (absQuantityVariance >= quantityThreshold * 1.5 || absDollarVariance >= dollarThreshold * 1.5) {
    return 'medium';
  }
  
  return 'low';
}
```

#### Testing Coverage

**Service Tests** (`usageCalculationService.test.js` - 23 passing tests)
- **Calculation Methods**: Recipe-based, historical average, AI-predicted
- **Actual Usage**: Snapshot analysis with purchase integration
- **Variance Priority**: Dave's business rules validation
- **Edge Cases**: Zero costs, negative usage, missing snapshots
- **Analysis Records**: Complete variance data structure

**Agent Tests** (`inventoryVarianceAgent.test.js` - 17 passing tests)  
- **Request Processing**: All capability endpoints
- **Business Intelligence**: Insights, recommendations, alerts
- **Investigation Workflow**: Assignment and resolution
- **Error Handling**: Unknown requests, auto-initialization
- **Integration**: Service interaction and data transformation

---

**✅ Task 8: Update Sequelize Models**

**Status**: COMPLETE ✅  
**Implementation Date**: September 23, 2025  
**Files**: 
- `backend/src/models/IngredientCategory.js` - NEW ltree-enabled hierarchical categories
- `backend/src/models/index.js` - NEW model management and associations  
- `backend/src/config/database.js` - Enhanced PostgreSQL ltree support
- `backend/tests/unit/models/sequelizeModelsUpdated.test.js` - 14 passing tests

#### Enhanced Sequelize Models

**New IngredientCategory Model** - PostgreSQL ltree hierarchical categories
```javascript
class IngredientCategory extends Model {
  // Hierarchical operations using ltree
  async getParentCategory() {
    const parentPath = this.path.split('.').slice(0, -1).join('.');
    return await IngredientCategory.findOne({ where: { path: parentPath } });
  }
  
  async getChildCategories() {
    return await IngredientCategory.findAll({
      where: sequelize.literal(`path ~ '${this.path}.*{1}'`) // Immediate children
    });
  }
  
  async getAllDescendants() {
    return await IngredientCategory.findAll({
      where: sequelize.literal(`path <@ '${this.path}'`) // All descendants
    });
  }
  
  getBreadcrumbs() {
    // Generate breadcrumb navigation for Dave's drilling interface
    const pathParts = this.path.split('.');
    return pathParts.map((part, i) => ({
      path: pathParts.slice(0, i + 1).join('.'),
      name: part.replace(/_/g, ' ').replace(/\b\w/g, l => l.toUpperCase())
    }));
  }
}
```

**Enhanced InventoryItem Model** - Hierarchical category integration
```javascript
class InventoryItem extends Model {
  static associate(models) {
    // New hierarchical category association
    InventoryItem.belongsTo(models.IngredientCategory, {
      foreignKey: 'categoryId',
      as: 'hierarchicalCategory'
    });
  }
  
  async getCategoryPath() {
    // Get full hierarchical path for Dave's drilling capabilities
    await this.reload({ 
      include: [{ model: IngredientCategory, as: 'hierarchicalCategory' }] 
    });
    return this.hierarchicalCategory?.path || this.category;
  }
  
  static async findHighValueItems(restaurantId) {
    return this.findAll({
      where: { restaurantId, highValueFlag: true, isActive: true },
      include: [{ model: IngredientCategory, as: 'hierarchicalCategory' }],
      order: [['unitCost', 'DESC']]
    });
  }
  
  static async getCategoryVarianceSummary(restaurantId, categoryPath = null) {
    // Dave's category drilling with ltree path filtering
    const whereClause = { restaurantId, isActive: true };
    if (categoryPath) {
      whereClause['$hierarchicalCategory.path$'] = { 
        [Op.like]: `${categoryPath}%` 
      };
    }
    
    return this.findAll({
      where: whereClause,
      include: [{ model: IngredientCategory, as: 'hierarchicalCategory' }],
      group: ['hierarchicalCategory.path'],
      attributes: [
        'hierarchicalCategory.path',
        [sequelize.fn('COUNT', sequelize.col('InventoryItem.id')), 'itemCount'],
        [sequelize.fn('AVG', sequelize.col('unitCost')), 'avgUnitCost'],
        [sequelize.fn('SUM', 
          sequelize.literal('CASE WHEN high_value_flag = true THEN 1 ELSE 0 END')
        ), 'highValueCount']
      ]
    });
  }
}
```

**Model Index System** - Centralized model management
```javascript
// backend/src/models/index.js
import sequelize from '../config/database.js';
import Restaurant from './Restaurant.js';
import IngredientCategory from './IngredientCategory.js'; // NEW
import InventoryItem from './InventoryItem.js';
// ... other models

const models = { Restaurant, IngredientCategory, InventoryItem, /* ... */ };

// Initialize all associations
Object.keys(models).forEach(modelName => {
  if (models[modelName].associate) {
    models[modelName].associate(models);
  }
});

// Add models to sequelize instance for easy access
Object.keys(models).forEach(modelName => {
  sequelize.models[modelName] = models[modelName];
});
```

#### Dave's Hierarchical Category System

**ltree Path Examples:**
- `produce` → `produce.leafy_greens` → `produce.leafy_greens.romaine`
- `spices` → `spices.premium` → `spices.premium.saffron`
- `dairy` → `dairy.cheese` → `dairy.cheese.hard_cheese`

**Category Tree Navigation:**
```javascript
// Build hierarchical tree for frontend drilling
const tree = await IngredientCategory.getCategoryTree();
// Returns nested structure for React components

// Search categories by name or path
const results = await IngredientCategory.searchCategories('saffron');

// Get category statistics for management dashboard
const stats = await IngredientCategory.getCategoryStats('produce.leafy_greens');
```

#### Database Configuration Enhancements

**PostgreSQL ltree Support:**
```javascript
// Enhanced dialectOptions for ltree compatibility
dialectOptions: {
  ssl: { /* SSL config */ },
  supportBigNumbers: true,
  bigNumberStrings: true
}

// ltree indexes created in migration:
// - GiST index for hierarchical queries
// - B-tree index for ancestor path queries  
// - Standard indexes for name and active status
```

#### Testing Coverage

**Model Tests** (`sequelizeModelsUpdated.test.js` - 14 passing tests)
- **IngredientCategory Model** (6 tests): ltree operations, breadcrumbs, tree building
- **Updated InventoryItem Model** (3 tests): category associations, high-value filtering
- **Dave's Business Logic Integration** (2 tests): variance priorities, category drilling
- **Model Integration Tests** (3 tests): path validation, depth calculation, breadcrumb generation

**Key Test Coverage:**
```javascript
test('should create hierarchical categories with ltree paths', async () => {
  // Validates ltree path structure and depth calculation
});

test('should find parent/child categories using ltree operators', async () => {
  // Tests PostgreSQL ltree ancestor/descendant queries
});

test('should support Dave\'s variance priorities with categories', async () => {
  // Validates business logic integration with hierarchical data
});
```

#### Production Integration

**API Endpoints** (Ready for implementation):
```javascript
// Calculate usage variance for period
POST /api/variance/calculate
{
  "periodId": 1,
  "method": "recipe_based",
  "recalculate": false
}

// Analyze period variance patterns
GET /api/variance/analyze/:periodId

// Get priority variance summary  
GET /api/variance/priority/:priority?period=1

// Investigation management
POST /api/variance/investigate
PUT /api/variance/resolve/:analysisId
```

**Dashboard Integration** (Data structures ready):
```javascript
// Variance summary for management dashboard
{
  "periodId": 1,
  "overview": {
    "totalItems": 45,
    "totalVarianceDollarValue": 234.56,
    "averageConfidence": 0.87
  },
  "priorityBreakdown": {
    "critical": 3,
    "high": 7,  
    "medium": 15,
    "low": 20
  },
  "alerts": [
    {
      "type": "critical_variance",
      "severity": "critical", 
      "count": 3,
      "message": "Critical variances detected requiring immediate investigation"
    }
  ]
}
```

#### Performance Characteristics

**Service Performance:**
- Batch processing: 100+ items per period in <5 seconds
- Memory efficient: Processes items individually to avoid large data loads
- Error resilient: Continues processing with partial failures
- Audit complete: Full calculation metadata and confidence scoring

**Agent Performance:**
- Request processing: <100ms for typical variance analysis
- Investigation workflow: Immediate status updates
- Business intelligence: Real-time insight generation
- Multi-period analysis: Optimized for historical trend queries

### **Next Phase Implementation Plan - Dave's Inventory Variance System**

**Current Status**: Core foundation complete (Tasks 1-8), ready for API and frontend development

#### **Phase 3: API Development** (In Progress - Task 9 Complete ✅)

**✅ Task 9: Period Management APIs** - COMPLETED
- **Files**: 
  - ✅ `backend/src/controllers/periodController.js` - 8 controller methods with business logic
  - ✅ `backend/src/routes/periods.js` - REST endpoints with express-validator validation
  - ✅ `backend/src/middleware/asyncHandler.js` - Error handling middleware
  - ✅ `backend/src/utils/validation.js` - Validation utilities
  - ✅ `backend/src/routes/index.js` - Route integration

- **API Endpoints Implemented**:
  - ✅ `POST /api/v1/periods` - Create new period with overlap validation
  - ✅ `GET /api/v1/periods` - List periods with filtering & pagination  
  - ✅ `GET /api/v1/periods/:id` - Get specific period details
  - ✅ `PUT /api/v1/periods/:id` - Update period information
  - ✅ `PUT /api/v1/periods/:id/activate` - Activate draft period
  - ✅ `PUT /api/v1/periods/:id/close` - Close active period (requires snapshots)
  - ✅ `POST /api/v1/periods/:id/snapshots` - Create beginning/ending inventory snapshots
  - ✅ `DELETE /api/v1/periods/:id` - Delete draft periods only

- **Business Logic Features**:
  - ✅ Period lifecycle: draft → active → closed status transitions
  - ✅ Overlap detection and conflict prevention
  - ✅ Comprehensive validation with detailed error messages
  - ✅ Audit trail with timestamps and user tracking
  - ✅ Snapshot management (beginning/ending inventory counts)
  - ✅ Async error handling with centralized error middleware

**☐ Task 10: Variance Analysis APIs**  
- **Files**: `backend/src/routes/variance.js`, `backend/src/controllers/varianceController.js`
- **Endpoints**: `POST /variance/period-analysis`, `GET /variance/categories`
- **Features**: Hierarchical category breakdown with Dave's priority system

**☐ Task 11: Investigation Workflow APIs**
- **Files**: `backend/src/routes/investigations.js`, `backend/src/controllers/investigationController.js`
- **Endpoints**: `POST /variance/investigate`, `PUT /variance/:id/resolve`
- **Features**: Assignment tracking and resolution workflow management

#### **Phase 4: Frontend Components** (In Progress)

**✅ Task 12: Period Selection Component** (COMPLETED - 97.8% Test Coverage)
- **Files**: `frontend/src/components/inventory/PeriodSelector/index.jsx`, validation hooks, Redux integration
- **Features**: Comprehensive period management with tabbed interface (periods + custom date ranges)
- **Integration**: Fully integrated into InventoryList (primary) and Dashboard (optional widget)
- **Redux State**: Complete state management with actions, selectors, loading states
- **Validation**: Custom hooks (usePeriodSelection, useDateRangeValidation) with business rules
- **Testing**: 132/135 tests passing (97.8% success rate) across component and integration tests
- **Architecture**: Production-ready with error handling, loading states, defensive coding
- **Documentation**: Complete usage guide, API integration patterns, troubleshooting

**☐ Task 13: Category Drilling Interface**
- **File**: `frontend/src/components/variance/CategoryDrilldown.jsx`
- **Features**: Hierarchical navigation with breadcrumbs and ltree-based drilling

**☐ Task 14: Variance Analysis Table**
- **File**: `frontend/src/components/variance/VarianceTable.jsx`  
- **Features**: Dual-metric sorting (quantity/dollar) with Dave's prioritization display

**☐ Task 15: Investigation Workflow UI**
- **File**: `frontend/src/components/variance/InvestigationWorkflow.jsx`
- **Features**: Assignment, tracking, and resolution interface for high-value variances

**☐ Task 16: Variance Dashboard**
- **File**: `frontend/src/components/variance/VarianceDashboard.jsx`
- **Features**: Executive summary cards, priority alerts, category breakdowns

#### **Phase 5: Testing & Performance** (Ready to Begin)

**☐ Task 17: API Integration Tests**
- **Files**: `backend/tests/integration/varianceAPI.test.js`, `backend/tests/integration/periodManagement.test.js`
- **Coverage**: All variance analysis endpoints with realistic data scenarios
- **Validation**: Period management workflow including snapshot creation

**☐ Task 18: Frontend Component Tests**
- **Files**: `frontend/tests/components/variance/`
- **Coverage**: Hierarchical drilling, variance tables, investigation workflow
- **Testing**: React component rendering and user interaction validation

**☐ Task 19: Performance Optimization**
- **Files**: Database indexes and query optimization
- **Focus**: Hierarchical queries, period analysis, variance sorting performance
- **Monitoring**: Dave's management queries and large-scale variance analysis

#### **Phase 6: Data & Scenario Testing** (Ready to Begin)

**☐ Task 20: Sample Data Generation**
- **File**: `backend/scripts/generate-variance-sample-data.js` 
- **Content**: Hierarchical categories, multiple restaurants, varied periods, diverse variance scenarios

**☐ Task 21: Dave's Test Scenarios**
- **File**: `backend/scripts/dave-test-scenarios.js`
- **Scenarios**: High-value items (saffron), low-value items (romaine), mixed variance patterns
- **Validation**: "I don't care about 20 lbs romaine, but 4oz saffron is $600" principle

#### **Ready-to-Implement Features**

**Database Foundation**: ✅ Complete
- All 10 migrations implemented and tested
- TheoreticalUsageAnalysis model with full business logic
- UsageCalculationService with multi-method calculation
- InventoryVarianceAgent with business intelligence

**Service Architecture**: ✅ Complete  
- Clean separation: models, services, agents
- Dependency injection for testability
- Dave's priority system fully implemented
- Investigation workflow ready for API integration

**Next Immediate Steps for Stability**:
1. **Implement Task 9** (Period Management APIs) - Foundation for all other features
2. **Implement Task 12** (Period Selection Component) - Core UI component
3. **Implement Task 17** (API Integration Tests) - Ensure reliability
4. **Commit and merge** the stable foundation

#### Future Enhancements (Ready for Integration)

**AI/ML Integration Points:**
```javascript
// Placeholder method ready for ML model integration
async calculateAIPredictedUsage(item, period) {
  // Enhanced historical analysis with ML metadata
  // Seasonal pattern recognition
  // Demand prediction integration
  // Quality score improvements
}
```

**Recipe System Integration:**
```javascript
// Service designed to integrate with future Recipe models
async getRecipeIngredients(restaurantId) {
  // Recipe model queries
  // Ingredient relationship mapping
  // Yield factor calculations
  // Sales data correlation
}
```

---

## Implementation Guides

### Square OAuth Connection UI (Issue #30)

**Overview**: Complete frontend implementation for Square POS OAuth integration, providing users with a seamless connection workflow from authorization through location selection.

#### Architecture

**Component Hierarchy:**
```
App.jsx (ErrorBoundary wrapper)
  └── SquareConnectionPage (orchestrator)
      ├── ConnectionButton (OAuth initiation)
      ├── ConnectionStatus (health monitoring)
      └── LocationSelector (multi-location selection)
```

**Data Flow:**
```
User Action → Component → Redux Thunk → API Service → Backend
                          ↓
                    State Update → UI Re-render
```

#### Redux State Management

**File**: `frontend/src/store/slices/squareConnectionSlice.js`

**State Structure:**
```javascript
{
  connectionStatus: null,  // Connection health status
  authorizationUrl: null,  // OAuth URL from backend
  locations: [],           // Available Square locations
  selectedLocationIds: [], // User-selected locations
  loading: {               // Granular loading states
    initiating: false,
    callback: false,
    status: false,
    locations: false,
    selecting: false,
    disconnecting: false,
    health: false
  },
  error: null              // Error messages
}
```

**Async Thunks** (7 total):
1. `initiateSquareConnection()` - Start OAuth flow
2. `handleSquareCallback(code, state)` - Process OAuth return
3. `fetchSquareStatus()` - Get connection status
4. `fetchSquareLocations()` - Retrieve available locations
5. `selectSquareLocations(locationIds)` - Save selected locations
6. `disconnectSquare()` - Remove integration
7. `checkSquareHealth()` - Verify connection health

**Key Selectors** (11 total):
```javascript
selectConnectionStatus(state)    // Get connection status
selectAuthorizationUrl(state)    // Get OAuth URL
selectSquareLocations(state)     // Get locations array
selectSelectedLocationIds(state) // Get selected IDs
selectSquareError(state)         // Get error message
selectIsInitiating(state)        // OAuth flow loading
selectIsProcessingCallback(state)// Callback processing
// ... and 4 more loading selectors
```

#### Components

**1. ConnectionButton** (`frontend/src/components/pos/square/ConnectionButton.jsx`)

**Purpose**: Initiate Square OAuth flow with visual feedback

**Key Features:**
- Dispatches `initiateSquareConnection` thunk
- Redirects to Square authorization URL
- Loading state with spinner icon
- Error handling with notistack notifications

**Usage Example:**
```jsx
import { ConnectionButton } from '../components/pos/square';

<ConnectionButton />
```

**2. ConnectionStatus** (`frontend/src/components/pos/square/ConnectionStatus.jsx`)

**Purpose**: Display connection health with management options

**Key Features:**
- Visual status badges (connected/disconnected/error)
- Location list display
- Disconnect button with confirmation
- Periodic health checks

**Props**: None (connects to Redux)

**3. LocationSelector** (`frontend/src/components/pos/square/LocationSelector.jsx`)

**Purpose**: Multi-location checkbox selection UI

**Key Features:**
- Search/filter functionality
- Select all/none toggle
- Validation (at least 1 location required)
- Loading/error/empty states

**State Management:**
- Local state for search term
- Redux for locations array and submission

**4. SquareConnectionPage** (`frontend/src/pages/SquareConnectionPage.jsx`)

**Purpose**: Main orchestration component managing OAuth flow

**Key Features:**
- OAuth callback detection via URL params
- View switching (connect → status → locations)
- URL cleanup after callback processing
- useCallback for effect dependencies

**View Logic:**
```javascript
if (!connectionStatus) {
  return <ConnectionButton />;
} else if (selectedLocationIds.length === 0) {
  return <LocationSelector />;
} else {
  return <ConnectionStatus />;
}
```

**5. ErrorBoundary** (`frontend/src/components/common/ErrorBoundary.jsx`)

**Purpose**: Catch and display React component errors gracefully

**Key Features:**
- Class component with getDerivedStateFromError
- Development error details display
- Refresh/home navigation buttons
- Console error logging

#### Routing Configuration

**Main Route** (`/settings/integrations/square`):
```jsx
<Route 
  path="/settings/integrations/square" 
  element={<SquareConnectionPage />} 
/>
```

**Callback Route** (`/settings/integrations/square/callback`):
```jsx
<Route 
  path="/settings/integrations/square/callback" 
  element={<SquareConnectionPage />} 
/>
```

**Navigation Link** (in `Layout.jsx`):
```jsx
{
  label: 'Settings',
  icon: Settings,
  path: '/settings',
  children: [
    {
      label: 'Square Integration',
      icon: Plug,
      path: '/settings/integrations/square'
    }
  ]
}
```

#### User Flow

1. **Navigation**: User clicks "Settings" → "Square Integration"
2. **Connection View**: Sees `ConnectionButton` component
3. **OAuth Initiation**: Clicks "Connect Square"
   - Redux dispatches `initiateSquareConnection`
   - Backend returns authorization URL
   - User redirected to Square OAuth page
4. **Authorization**: User approves Square permissions
5. **Callback Handling**: Square redirects to callback route
   - `SquareConnectionPage` detects code/state params
   - Dispatches `handleSquareCallback` thunk
   - Backend exchanges code for access token
   - Success notification shown
6. **Location Selection**: Component switches to `LocationSelector`
   - Fetches available Square locations
   - User selects locations to sync
   - Submits selection
7. **Status View**: Component switches to `ConnectionStatus`
   - Shows connection health
   - Displays selected locations
   - Provides disconnect option

#### Testing

**Test File**: `frontend/tests/store/squareConnectionSlice.test.js`

**Coverage**: 32 unit tests (100% passing)

**Test Categories:**
- Initial state validation
- Synchronous actions (5 tests)
- Async thunk success cases (7 tests)
- Async thunk failure cases (7 tests)
- Selectors (11 tests)
- State transitions (2 tests)

**Example Test:**
```javascript
describe('initiateSquareConnection', () => {
  it('should handle successful connection initiation', async () => {
    const mockAuthUrl = 'https://connect.squareup.com/oauth2/authorize...';
    mockApi.initiateSquareConnection.mockResolvedValue({
      data: { authorizationUrl: mockAuthUrl }
    });
    
    await store.dispatch(initiateSquareConnection());
    
    const state = store.getState().squareConnection;
    expect(state.authorizationUrl).toBe(mockAuthUrl);
    expect(state.loading.initiating).toBe(false);
    expect(state.error).toBeNull();
  });
});
```

#### Error Handling

**Error Boundary**: Wraps all routes in `App.jsx`
```jsx
<ErrorBoundary>
  <Routes>
    {/* All routes */}
  </Routes>
</ErrorBoundary>
```

**API Error Handling**: Consistent pattern across all thunks
```javascript
try {
  const response = await api.someEndpoint();
  return response.data;
} catch (error) {
  return rejectWithValue(error.response?.data?.message || 'Operation failed');
}
```

**User Notifications**: notistack integration in `main.jsx`
```jsx
<SnackbarProvider 
  maxSnack={3}
  anchorOrigin={{ vertical: 'top', horizontal: 'right' }}
  autoHideDuration={4000}
>
  <App />
</SnackbarProvider>
```

#### Mobile Responsiveness

All components use Tailwind CSS responsive classes:
- `sm:`, `md:`, `lg:` breakpoints for layout adjustments
- Touch-friendly button sizes (minimum 44px)
- Readable font sizes on small screens
- Proper spacing and padding across devices

**Example:**
```jsx
<div className="grid gap-2 sm:grid-cols-2 lg:grid-cols-3">
  {/* Responsive grid layout */}
</div>
```

#### Quality Metrics

- **Frontend Tests**: 167/167 passing (100%)
- **Backend Tests**: 399/399 passing (100%)
- **Redux Slice Tests**: 32/32 passing (100%)
- **Build Time**: 2.38s average
- **Bundle Size**: 962.71 kB (optimized for production)
- **Dev Server**: Running without errors

#### API Integration

**Backend Endpoints Used:**
- `POST /api/v1/pos/square/connect` - Initiate OAuth
- `POST /api/v1/pos/square/callback` - Exchange code for token
- `GET /api/v1/pos/square/status` - Get connection status
- `GET /api/v1/pos/square/locations` - Fetch locations
- `POST /api/v1/pos/square/locations/select` - Save location selection
- `DELETE /api/v1/pos/square/disconnect` - Remove integration
- `GET /api/v1/pos/square/health` - Check connection health

**API Service** (`frontend/src/services/api.js`):
```javascript
export const initiateSquareConnection = () => 
  api.post('/pos/square/connect');

export const handleSquareCallback = (code, state) => 
  api.post('/pos/square/callback', { code, state });

// ... other methods
```

#### Future Enhancements

- **E2E Testing**: Playwright tests for full OAuth flow
- **Sandbox Testing**: Square sandbox account integration
- **Error Recovery**: Automatic retry on network failures
- **Location Sync Status**: Real-time sync progress indicators
- **Webhook Integration**: Event notifications from Square
- **Multi-restaurant Support**: Location mapping for multiple restaurants

---

### Setting Up Development Environment

#### Prerequisites
- Node.js 18+
- PostgreSQL 14+
- Redis (optional, currently bypassed for development speed)
- Docker (for containerization and PostgreSQL)

#### Quick Start
```bash
# Clone and install dependencies
git clone <repository>
cd CostFX
npm install

# Set up workspace (installs all dependencies)
npm run setup:workspace

# Start development environment
npm run dev
```

#### Docker Deployment (Verified September 28, 2025)
**Full Stack Deployment with Fresh Database**:
```bash
# Clean deployment with all services
docker compose -f docker-compose.test.yml down -v
docker compose -f docker-compose.test.yml up --build -d

# Verify all services are healthy
docker compose -f docker-compose.test.yml ps

# Check API endpoints
curl http://localhost:3002/health
curl http://localhost:3002/api/v1/agents/status

# Access frontend
open http://localhost:8081
```

**Deployment Verification Results**:
- ✅ **All 4 Services Healthy**: backend, frontend, postgres, redis
- ✅ **Database Operations**: Migrations completed, seed data loaded
- ✅ **API Endpoints**: All agent endpoints responding on localhost:3002
- ✅ **Frontend Application**: React app serving on localhost:8081
- ✅ **Database Seeding**: Demo Restaurant and inventory data created

#### Environment Configuration
Create `.env` files in both `backend/` and `frontend/` directories:

**Root `.env`:**
```env
NODE_ENV=development
PORT=3001
DATABASE_URL=postgresql://username:password@localhost:5432/restaurant_ai
# REDIS_URL=redis://localhost:6379  # Disabled for development speed
JWT_SECRET=your-jwt-secret
OPENAI_API_KEY=your-openai-key
```

**Current Development Configuration (September 2025)**:
- **PostgreSQL**: Required, runs via `docker-compose up -d db`
- **Redis**: Bypassed for faster development startup
- **Ports**: Backend (3001), Frontend (3000)
- **SSL**: Disabled for local PostgreSQL connection

**To Enable Redis** (if needed):
```bash
# Uncomment REDIS_URL in .env
REDIS_URL=redis://localhost:6379

# Start Redis container
docker-compose up -d redis
```

### Adding New AI Agents

#### Step 1: Create Agent Class
```javascript
// backend/src/agents/NewAgent.js
import BaseAgent from './BaseAgent.js';

export default class NewAgent extends BaseAgent {
  constructor() {
    super('NewAgent', ['capability1', 'capability2']);
  }

  async process(request) {
    // Implementation logic
    return {
      success: true,
      data: result,
      metadata: {
        processingTime: Date.now() - startTime,
        confidence: 0.95
      }
    };
  }
}
```

#### Step 2: Register in AgentManager
```javascript
// backend/src/agents/AgentManager.js
import NewAgent from './NewAgent.js';

export default class AgentManager {
  constructor() {
    this.agents = new Map([
      ['cost', new CostAgent()],
      ['inventory', new InventoryAgent()],
      ['forecast', new ForecastAgent()],
      ['new', new NewAgent()] // Add here
    ]);
  }
}
```

#### Step 3: Add Service Methods
```javascript
// backend/src/agents/AgentService.js
export default class AgentService {
  static async processNewRequest(data) {
    return await this.processAgentRequest('new', 'process', data);
  }
}
```

#### Step 4: Create API Routes
```javascript
// backend/src/routes/agents.js
router.post('/new/process', async (req, res, next) => {
  try {
    const result = await AgentService.processNewRequest(req.body);
    res.json(result);
  } catch (error) {
    next(error);
  }
});
```

### Testing Implementation

**Current Setup**: Vitest with native ES modules support (migrated from Jest in September 2025)

#### Test Structure
```
backend/tests/
├── setup.js              # Vitest configuration with mocks
├── vitest.config.js       # Test environment configuration
├── fixtures/              # Test data
├── unit/                  # Unit tests
│   ├── agents/           # Agent-specific tests (some tests need implementation updates)
│   ├── models/           # Model tests
│   └── services/         # Service tests  
└── integration/          # Integration tests (some routes need implementation)
    └── api/              # API endpoint tests
```

**Current Test Status**: 59/102 tests passing
- ✅ All unit tests for error handling, logging, and controllers pass
- ✅ ForecastAgent tests fully operational (24/24 passing)
- ⚠️ InventoryAgent tests need method implementation alignment
- ⚠️ Integration tests failing due to missing API endpoints (expected)

#### Writing Agent Tests with Vitest
```javascript
// backend/tests/unit/agents/NewAgent.test.js
import { describe, test, expect, vi, beforeEach } from 'vitest';
import NewAgent from '../../../src/agents/NewAgent.js';

// Mock dependencies using Vitest
vi.mock('../../src/models/SomeModel.js', () => ({
  default: {
    findAll: vi.fn()
  }
}));

describe('NewAgent', () => {
  let agent;

  beforeEach(() => {
    agent = new NewAgent();
  });

  test('should process request successfully', async () => {
    const testData = { /* test data */ };
    const result = await agent.process(testData);
    
    expect(result.success).toBe(true);
    expect(result.data).toBeDefined();
    expect(result.metadata.confidence).toBeGreaterThan(0);
  });
});
```

#### Test Commands
```bash
# Run all tests (Vitest)
npm test                    # Runs vitest run (CI mode)
npm run test:watch         # Runs vitest (watch mode)  
npm run test:coverage      # Runs with coverage report

# Backend testing with database setup
npm run test:setup         # Set up test database
npm run test:integration   # Run integration tests only
```

#### Advanced Test Architecture - Elegant Stateful Mock System ✅

**Location**: `backend/tests/setup.js`  
**Achievement**: Sophisticated test mock factory restored and enhanced (September 29, 2025)

The system implements an elegant stateful mock factory pattern that provides sophisticated database layer testing without actual database connections:

```javascript
// Core Factory Pattern with Shared Data Stores
function createStatefulMockModel(modelName, {
  defaultValues = {},
  validators = {},
  relationships = {},
  instanceMethods = {}
}) {
  const dataStore = new Map(); // Shared state across all mock instances
  let nextId = 1;

  // Mock constructor with full CRUD operations
  const MockModel = {
    // Static Methods (Class-level operations)
    create: vi.fn(async (data) => {
      const validatedData = applyValidation(data, validators);
      const record = {
        id: nextId++,
        ...defaultValues,
        ...validatedData,
        created_at: new Date(),
        updated_at: new Date()
      };
      dataStore.set(record.id, record);
      return createMockInstance(record, instanceMethods);
    }),

    findAll: vi.fn(async (options = {}) => {
      // Advanced filtering, sorting, and relationship loading
      let results = Array.from(dataStore.values());
      // Apply where conditions, include relationships, pagination
      return results.map(record => createMockInstance(record, instanceMethods));
    }),

    // Instance Methods (Record-level operations)  
    save: vi.fn(async function() {
      this.updated_at = new Date();
      dataStore.set(this.id, { ...this });
      return this;
    })
  };

  return MockModel;
}
```

**Key Features**:
- ✅ **Stateful Data Persistence**: Shared Map stores maintain data across test operations
- ✅ **Full CRUD Operations**: Create, Read, Update, Delete with proper state management
- ✅ **Type Coercion & Validation**: Automatic data type conversion and validation
- ✅ **Relationship Simulation**: Mock associations and includes without database queries
- ✅ **Instance Methods**: Dynamic method attachment for model-specific behavior
- ✅ **Business Logic Testing**: Clean separation between data layer and business validation

**Implementation Example**:
```javascript
// tests/setup.js - Model Factory Registration
export const mockModels = {
  InventoryPeriod: createStatefulMockModel('InventoryPeriod', {
    defaultValues: {
      status: 'draft',
      is_active: true,
      restaurant_id: 1
    },
    validators: {
      name: (value) => typeof value === 'string' && value.length > 0,
      start_date: (value) => value instanceof Date || !isNaN(Date.parse(value))
    },
    instanceMethods: {
      // Business logic methods added dynamically
      canTransitionTo: function(newStatus) {
        const validTransitions = {
          draft: ['active'],
          active: ['closed'],
          closed: []
        };
        return validTransitions[this.status]?.includes(newStatus) || false;
      },
      
      getSnapshotCompleteness: function() {
        return {
          hasBeginning: this.beginning_snapshots_count > 0,
          hasEnding: this.ending_snapshots_count > 0,
          isComplete: this.beginning_snapshots_count > 0 && this.ending_snapshots_count > 0
        };
      }
    }
  })
};
```

**Benefits Achieved**:
- ✅ **Perfect Test Isolation**: Each test starts with clean state, no database dependencies
- ✅ **Fast Test Execution**: 399/399 tests complete in <1 second without I/O operations
- ✅ **Business Logic Focus**: Tests validate business rules, not database mechanics
- ✅ **Maintainable Architecture**: Changes to mock factory update all tests consistently
- ✅ **Realistic Data Simulation**: Proper relationship handling and data type management

**Integration with Enhanced Models**:
The mock system seamlessly integrates with enhanced Sequelize models like `InventoryPeriod.js`:

```javascript
// src/models/InventoryPeriod.js - Enhanced with missing methods
class InventoryPeriod extends Model {
  // Business logic methods that work with both real DB and mocks
  canTransitionTo(newStatus) {
    const validTransitions = {
      draft: ['active'],
      active: ['closed'], 
      closed: []
    };
    return validTransitions[this.status]?.includes(newStatus) || false;
  }

  getSnapshotCompleteness() {
    return {
      hasBeginning: this.beginning_snapshots_count > 0,
      hasEnding: this.ending_snapshots_count > 0,
      isComplete: this.beginning_snapshots_count > 0 && this.ending_snapshots_count > 0
    };
  }
}
```

**Test Execution Results**:
- ✅ **399/399 tests passing** (100% success rate)
- ✅ **All 22 test files operational** with consistent mock behavior
- ✅ **Comprehensive coverage** across unit tests, integration tests, and service layer tests
- ✅ **Fast execution**: Complete test suite runs in under 1 second

### PeriodSelector Component Implementation

**Status**: ✅ **COMPLETED** (September 2025) - 97.8% Test Coverage (132/135 tests passing)

The PeriodSelector is a comprehensive React component providing period management functionality for inventory analysis, fully integrated with Redux state management.

#### Component Architecture

**Primary Files**:
- `frontend/src/components/inventory/PeriodSelector/index.jsx` - Main component with tabbed interface
- `frontend/src/hooks/usePeriodSelection.js` - Period management logic and validation
- `frontend/src/hooks/useDateRangeValidation.js` - Date range validation with business rules
- `frontend/src/store/slices/inventorySlice.js` - Redux state management

**Integration Points**:
- **InventoryList** (`frontend/src/components/inventory/InventoryList.jsx`) - Primary inventory management interface
- **Dashboard** (`frontend/src/components/dashboard/Dashboard.jsx`) - Optional period selection widget

#### Implementation Example

```jsx
import PeriodSelector from './components/inventory/PeriodSelector';
import { useSelector, useDispatch } from 'react-redux';
import { selectSelectedPeriod, selectSelectedDateRange } from '../store/slices/inventorySlice';

function InventoryManagement() {
  const selectedPeriod = useSelector(selectSelectedPeriod);
  const selectedDateRange = useSelector(selectSelectedDateRange);

  return (
    <div className="inventory-management">
      <PeriodSelector
        restaurantId={1}
        selectedPeriod={selectedPeriod}
        selectedDateRange={selectedDateRange}
        onPeriodSelect={(period) => console.log('Selected:', period)}
        onDateRangeSelect={(dateRange) => console.log('Date range:', dateRange)}
        showCreateButton={true}
        showDateRangePicker={true}
        placeholder="Select analysis period..."
      />
      
      {selectedPeriod && (
        <div className="period-analysis">
          <h3>Analysis for {selectedPeriod.periodName}</h3>
          {/* Period-based inventory metrics */}
        </div>
      )}
    </div>
  );
}
```

#### Redux Integration

**State Structure**:
```javascript
inventory: {
  periodSelection: {
    periods: [],                    // Available periods
    selectedPeriod: null,           // Currently selected period
    selectedDateRange: null,        // Custom date range selection
    filters: {
      restaurantId: null,
      periodTypes: ['weekly', 'monthly', 'custom'],
      statusFilter: ['draft', 'active', 'closed'],
      searchTerm: ''
    },
    loading: false,
    error: null
  }
}
```

**Key Actions & Selectors**:
```javascript
// Actions
dispatch(fetchPeriods(restaurantId));
dispatch(setSelectedPeriod(period));
dispatch(setSelectedDateRange(dateRange));

// Selectors
const periods = useSelector(selectPeriods);
const selectedPeriod = useSelector(selectSelectedPeriod);
const loading = useSelector(selectPeriodLoading);
```

#### Validation Features

- **Period Validation**: Date range validation, overlap detection, business rules
- **Date Range Validation**: Range limits (1-365 days), weekend handling, future date prevention
- **Business Logic**: Type-specific validation for weekly vs monthly periods

#### Production Features

- ✅ **Error Handling**: Defensive coding with null checks and fallbacks
- ✅ **Loading States**: User feedback during API operations  
- ✅ **Accessibility**: Keyboard navigation and screen reader support
- ✅ **Responsive Design**: Mobile-friendly tabbed interface
- ✅ **Integration**: Seamless Redux state management across components

### Database Migrations

#### ⚠️ CRITICAL: ES Modules Pattern

**This backend uses ES modules (`"type": "module"` in package.json). Migrations MUST use ES module syntax!**

```javascript
/* eslint-disable camelcase */

// ✅ CORRECT - ES Modules
export const up = async (pgm) => {
  pgm.createTable('my_table', {
    id: { type: 'serial', primaryKey: true, notNull: true },
    name: { type: 'varchar(255)', notNull: true }
  });
};

export const down = async (pgm) => {
  pgm.dropTable('my_table');
};

// ❌ WRONG - CommonJS (causes "exports is not defined in ES module scope" error)
exports.up = async function (db) {
  // This will FAIL! Don't use exports.up in ES module projects
};
```

**Why this matters:** We hit this issue repeatedly. Always check existing migrations for the pattern.

#### ⚠️ CRITICAL: New Sequelize Models Must Be Registered in Test Mocks

**When you create new Sequelize models, you MUST update `backend/tests/setup.js` or tests will fail with cryptic errors like "Model.belongsTo is not a function".**

The test suite uses Vitest mocks to avoid database dependencies during unit tests. Every model needs two additions:

**1. Add to `sharedDataStores` Map:**
```javascript
const sharedDataStores = {
  Restaurant: new Map(),
  InventoryItem: new Map(),
  // ... existing models ...
  
  // ✅ ADD YOUR NEW MODELS HERE
  SquareCategory: new Map(),
  SquareMenuItem: new Map()
};
```

**2. Add `vi.mock()` call for each model file:**
```javascript
// ✅ ADD MOCK FOR EACH NEW MODEL
vi.mock('../src/models/SquareCategory.js', () => ({
  default: createStatefulMockModel('SquareCategory')
}));

vi.mock('../src/models/SquareMenuItem.js', () => ({
  default: createStatefulMockModel('SquareMenuItem')
}));
```

**Common Error:** If you forget this, you'll get errors during test runs:
```
TypeError: SquareCategory.belongsTo is not a function
  at Function.associate (src/models/SquareCategory.js:37:20)
  at src/models/index.js:44:23
```

**Why this happens:** The test environment mocks all models to avoid database connections. When `models/index.js` tries to call `associate()` on unmocked models, Sequelize's Model methods (belongsTo, hasMany, etc.) aren't available because the mock wasn't created.

**Solution:** Always add new models to `tests/setup.js` immediately after creating the model file. This ensures test mocks stay in sync with actual models.

**Pro tip:** Search `tests/setup.js` for "sharedDataStores" and "vi.mock('../src/models/" to find the two locations that need updates.

#### Creating Migrations
```bash
# Create new migration
npm run migrate:create <migration-name>

# Run migrations
npm run migrate:up

# Rollback migration
npm run migrate:down
```

#### Migration Template
```javascript
// backend/migrations/YYYYMMDD-create-new-table.js
exports.up = async function(pgm) {
  pgm.createTable('new_table', {
    id: {
      type: 'serial',
      primaryKey: true,
      notNull: true
    },
    name: {
      type: 'varchar',
      notNull: true
    },
      allowNull: false
    },
    createdAt: {
      allowNull: false,
      type: Sequelize.DATE
    },
    updatedAt: {
      allowNull: false,
      type: Sequelize.DATE
    }
  });
};

export const down = async (queryInterface, Sequelize) => {
  await queryInterface.dropTable('NewTable');
};
```

---

## Technical Solutions

### Production Deployment Issue Resolution (September 19, 2025)

**Problem**: ForecastAgent failing in production with "Network Error" due to mixed content security policy and backend container failures.

**Root Cause Analysis**:
1. **Mixed Content Error**: Frontend built with incorrect API URL (`https://cost-fx.com/api/v1`) causing HTTPS→HTTP calls
2. **Backend Environment Variables**: Enhanced env-var validation requiring `POSTGRES_PASSWORD` even when `DATABASE_URL` was provided
3. **ECS Task Failures**: 1486+ failed backend tasks due to missing environment variable validation

**Solutions Implemented**:

#### 1. Frontend Build Configuration Fix
**File**: `.github/workflows/app-deploy.yml`
```yaml
# BEFORE (incorrect)
--build-arg VITE_API_URL="https://cost-fx.com/api/v1"

# AFTER (correct)
--build-arg VITE_API_URL="https://www.cost-fx.com/api/v1"
```

#### 2. Backend Database Configuration Enhancement
**File**: `backend/src/config/database.js`
```javascript
// Enhanced to make POSTGRES_PASSWORD optional when DATABASE_URL is provided
const databaseUrl = env.get('DATABASE_URL').asUrlString();

const dbConfig = {
  url: databaseUrl,
  // Individual credentials only required if DATABASE_URL not provided
  password: env.get('POSTGRES_PASSWORD').asString(), // No longer .required()
  // ... other config
};

// Validation: require either DATABASE_URL or individual credentials
if (!dbConfig.url && !dbConfig.password) {
  throw new Error('Either DATABASE_URL or POSTGRES_PASSWORD must be provided');
}
```

#### 3. Production Debugging Methodology
**CloudWatch Log Analysis**:
```bash
# Identify failed tasks
aws ecs describe-services --cluster costfx-dev --services costfx-dev-backend

# Examine task failure reasons
aws ecs describe-tasks --cluster costfx-dev --tasks <task-arn>

# Check application logs
aws logs get-log-events --log-group-name "/ecs/costfx-dev-backend" \
  --log-stream-name "ecs/backend/<task-id>"
```

**Error Pattern Identified**:
```javascript
EnvVarError: env-var: "POSTGRES_PASSWORD" is a required variable, but it was not set
```

**Resolution Impact**:
- ✅ Backend containers now start successfully with DATABASE_URL only
- ✅ Frontend builds with correct HTTPS API URL preventing mixed content errors
- ✅ Production ForecastAgent functionality restored
- ✅ ECS deployment stability achieved (0 failed tasks after fix)

### Centralized Configuration Management

**Problem**: Hardcoded ports and URLs scattered across test files, application code, and configuration files made maintenance difficult and error-prone.

**Solution**: Implemented centralized configuration system with environment-aware settings:

#### Backend Configuration (`backend/src/config/settings.js`)
```javascript
const settings = {
  // Server
  port: process.env.PORT || 3001,
  nodeEnv: process.env.NODE_ENV || 'development',
  
  // URLs
  frontendUrl: process.env.FRONTEND_URL || 'http://localhost:3000',
  baseUrl: process.env.BASE_URL || `http://localhost:${process.env.PORT || 3001}`,
  apiPath: '/api/v1',
  
  // CORS allowed origins
  corsOrigins: [
    'http://localhost:3000',  // Frontend dev server
    'http://localhost:3001',  // Backend dev server 
    'http://localhost:3002',  // Docker dev server
    process.env.FRONTEND_URL
  ].filter(Boolean)
};
```

#### Frontend Configuration (`frontend/src/config/settings.js`)
```javascript
export function getApiConfig() {
  return {
    baseURL: import.meta.env.VITE_API_URL || 'http://localhost:3001/api/v1',
    timeout: 10000,
    headers: {
      'Content-Type': 'application/json'
    }
  };
}
```

#### Shared Test Configuration (`shared/src/config/testConfig.js`)
```javascript
export const testConfig = {
  backend: {
    port: 3001,
    apiUrl: 'http://localhost:3001/api/v1'
  },
  frontend: {
    port: 3000,
    baseUrl: 'http://localhost:3000'
  }
};
```

**Benefits**:
- ✅ Single source of truth for all ports and URLs
- ✅ Environment-specific configurations
- ✅ Easy to change ports across entire application
- ✅ Consistent test environments
- ✅ No more hunting through files for hardcoded values

### Complete Test Suite Implementation

**Problem**: Test failures due to incomplete InventoryAgent implementation, route mounting issues, and model mocking problems.

**Solution**: Systematic reconstruction and proper testing infrastructure:

#### InventoryAgent Complete Rebuild
- **Proper Capabilities Array**: `['track_inventory', 'predict_reorder', 'monitor_expiration', 'analyze_waste', 'optimize_stock']`
- **All Required Methods**: Implemented `trackInventoryLevels()`, `predictReorderNeeds()`, `monitorExpirationDates()`, `analyzeWastePatterns()`, `optimizeStockLevels()`
- **Correct Data Structures**: Aligned response formats with test expectations
- **Result**: 21/21 InventoryAgent tests passing

#### Integration Test Infrastructure
- **Route Mounting Fix**: Added legacy API mount (`app.use('/api', routes)`) for test compatibility
- **Model Mocking Enhancement**: Added missing `findAndCountAll` method to Restaurant model mock
- **Test Data Setup**: Proper mock data and behavior for different test scenarios
- **Result**: 46/46 integration tests passing

**Final Achievement**: 151/151 tests passing (100% success rate)

### ECS Deployment Performance & Container Stability (September 24, 2025)

**Problem**: ECS deployments taking 18+ minutes and eventually failing after 30 minutes with "Resource is not in the state servicesStable" error.

**Root Cause Analysis**:
1. **Aggressive Health Checks**: 30-second intervals with 5-second timeouts causing premature failures
2. **Container Startup Issues**: `PGSSLMODE="no-verify"` invalid for stricter env-var validation in recent code
3. **SSL Configuration Mismatch**: Application validation requiring valid PostgreSQL SSL modes

**Solutions Implemented**:

#### 1. Health Check Optimization
**File**: `deploy/terraform/ecs-complete.tf`
```terraform
health_check {
  enabled             = true
  healthy_threshold   = 2
  interval            = 60    # Increased from 30s
  matcher             = "200"
  path                = "/api/v1/"
  port                = "traffic-port"
  protocol            = "HTTP"
  timeout             = 10    # Increased from 5s
  unhealthy_threshold = 5     # Increased from 3
}
```

#### 2. SSL Configuration Fix
**File**: `deploy/terraform/ecs-complete.tf`
```terraform
# BEFORE (invalid)
{
  name  = "PGSSLMODE"
  value = "no-verify"  # Invalid enum value
}

# AFTER (valid)
{
  name  = "PGSSLMODE" 
  value = "require"    # Valid PostgreSQL SSL mode
}
```

**Resolution Impact**:
- ✅ **Deployment Time**: Reduced from 18+ minutes to ~2 minutes
- ✅ **Container Stability**: No more startup crashes due to invalid PGSSLMODE
- ✅ **Health Check Reliability**: Extended timeouts prevent false positives
- ✅ **Production Stability**: Both services running 2/2 tasks healthy

### Redis Configuration Management for Development Speed

**Problem**: Local development experiencing Redis connection errors (`ECONNREFUSED`) slowing down `npm run dev` startup.

**Root Cause**: Default Redis URL in settings causing client creation even when Redis not needed for development.

**Solution**: Implemented graceful Redis bypass system:

#### 1. Settings Configuration Update
**File**: `backend/src/config/settings.js`
```javascript
// BEFORE (always creates Redis client)
redisUrl: process.env.REDIS_URL || 'redis://localhost:6379',

// AFTER (only when explicitly set)
redisUrl: process.env.REDIS_URL, // No default - only use if explicitly set
```

#### 2. Environment Configuration
**File**: `.env`
```bash
# BEFORE (active)
REDIS_URL=redis://localhost:6379

# AFTER (disabled for development speed)
# REDIS_URL=redis://localhost:6379  # Disabled for development speed
```

#### 3. Graceful Degradation Logic
**File**: `backend/src/config/redis.js`
```javascript
const redis = REDIS_URL ? createClient({ url: REDIS_URL }) : null;

export async function connectRedis() {
  if (!redis) {
    logger.info('ℹ️ REDIS_URL not set; skipping Redis connection');
    return;
  }
  // ... connection logic
}
```

**Re-enabling Redis**:

**Development**:
```bash
# Uncomment in .env
REDIS_URL=redis://localhost:6379

# Start Redis container
docker-compose up -d redis
```

**Production**:
```bash
# Uncomment resources in deploy/terraform/database.tf
# Uncomment aws_ssm_parameter.redis_url in deploy/terraform/ssm-parameters.tf
terraform apply
```

**Benefits**:
- ✅ **Fast Development Startup**: No Redis connection delays
- ✅ **Graceful Degradation**: Application runs without caching
- ✅ **Easy Re-enabling**: Simple configuration changes
- ✅ **Production Ready**: Redis infrastructure remains available

### ES Modules + Jest Configuration

**Problem**: Jest doesn't natively support ES modules, causing failures with modern JavaScript imports.

**Solution**: Configure Jest with Babel transformation:

```javascript
// backend/jest.config.js
export default {
  testEnvironment: 'node',
  transform: {
    '^.+\\.js$': 'babel-jest'
  },
  moduleNameMapper: {
    '^(\\.{1,2}/.*)\\.js$': '$1'
  },
  setupFilesAfterEnv: ['<rootDir>/tests/setup.js'],
  testMatch: ['**/tests/**/*.test.js'],
  collectCoverageFrom: [
    'src/**/*.js',
    '!src/index.js'
  ],
  coverageDirectory: 'coverage',
  verbose: true
};
```

### Docker Multi-Stage Builds

**Problem**: Large Docker images with unnecessary development dependencies.

**Solution**: Multi-stage builds for optimized production containers:

```dockerfile
# Dockerfile.backend
FROM node:18-alpine AS base
WORKDIR /app
COPY package*.json ./

FROM base AS development
RUN npm ci
COPY . .
EXPOSE 5000
CMD ["npm", "run", "dev"]

FROM base AS production
RUN npm ci --only=production && npm cache clean --force
COPY . .
EXPOSE 5000
CMD ["npm", "start"]
```

### Database Connection Pooling

**Problem**: Database connection limits in production.

**Solution**: Configured connection pooling:

```javascript
// backend/src/config/database.js
const config = {
  development: {
    dialect: 'postgres',
    host: process.env.DB_HOST || 'localhost',
    pool: {
      max: 5,
      min: 0,
      acquire: 30000,
      idle: 10000
    }
  },
  production: {
    dialect: 'postgres',
    host: process.env.DB_HOST,
    pool: {
      max: 20,
      min: 5,
      acquire: 30000,
      idle: 10000
    }
  }
};
```

### Error Handling Patterns

**Centralized Error Handler**:
```javascript
// backend/src/middleware/errorHandler.js
export const errorHandler = (err, req, res, next) => {
  const { statusCode = 500, message } = err;
  
  logger.error({
    error: err.message,
    stack: err.stack,
    url: req.url,
    method: req.method
  });

  res.status(statusCode).json({
    success: false,
    error: message,
    ...(process.env.NODE_ENV === 'development' && { stack: err.stack })
  });
};
```

---

## Development Environment

### NPM Workspace Configuration

The project uses NPM workspaces for managing the monorepo structure:

```json
// package.json (root)
{
  "name": "costfx",
  "workspaces": [
    "backend",
    "frontend", 
    "shared"
  ],
  "scripts": {
    "dev": "concurrently \"npm run dev --workspace=backend\" \"npm run dev --workspace=frontend\"",
    "build": "npm run build --workspaces",
    "test": "npm run test --workspaces",
    "lint": "npm run lint --workspaces"
  }
}
```

### Development Scripts

| Command | Purpose |
|---------|---------|
| `npm run dev` | Start both backend and frontend development servers |
| `npm run build` | Build both applications for production |
| `npm run test` | Run all test suites |
| `npm run lint` | Run ESLint across all workspaces |
| `npm run migrate` | Run database migrations |
| `npm run seed` | Seed database with test data |

### Hot Reload Configuration

**Backend** (using nodemon):
```json
// backend/nodemon.json
{
  "watch": ["src"],
  "ext": "js,json",
  "ignore": ["tests/**/*"],
  "exec": "node src/index.js"
}
```

**Frontend** (using Vite):
```javascript
// frontend/vite.config.js
export default defineConfig({
  server: {
    port: 3000,
    proxy: {
      '/api': 'http://localhost:5000'
    }
  },
  build: {
    outDir: 'dist',
    sourcemap: true
  }
});
```

---

## Deployment Guide

### Recent Updates (September 2025)

#### OIDC Authentication Implementation (September 18, 2025)
- **Security Enhancement**: Eliminated AWS access keys from GitHub Actions workflows
- **OIDC Provider**: Configured AWS OIDC provider for token.actions.githubusercontent.com
- **IAM Role**: Created GitHubActionsRole-CostFX with least-privilege deployment permissions
- **Workflow Updates**: Updated `.github/workflows/app-deploy.yml` to use role-based authentication
- **Container Health**: Fixed ECS health check issues and environment variable configuration
- **Infrastructure as Code**: All OIDC configuration managed through Terraform

#### Key OIDC Configuration Details
```yaml
# GitHub Actions workflow OIDC configuration
permissions:
  id-token: write
  contents: read

- name: Configure AWS credentials
  uses: aws-actions/configure-aws-credentials@v4
  with:
    role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
    role-session-name: github-actions-deploy
    aws-region: us-west-2
```

**AWS IAM Role ARN**: `arn:aws:iam::568530517605:role/GitHubActionsRole-CostFX`
**Trust Policy**: Configured for repository `akisma/CostFX` with branch restrictions
**Permissions**: ECS, ECR, SSM, and CloudWatch access for deployments

#### Infrastructure Health Resolution
- **Health Check Fix**: Changed ECS health check from `/api/v1/` to `/health` endpoint
- **Environment Variables**: Added missing OPENAI_API_KEY to ECS task definitions
- **Container Stability**: All ECS services now healthy and responsive
- **Load Balancer**: Health checks passing consistently across all targets

#### Jest to Vitest Migration
- **Migration Completed**: Backend testing migrated from Jest to Vitest for better ES modules support
- **Current Status**: 59/102 tests passing (improvement from failing Jest tests)
- **Key Changes**:
  - `package.json`: Updated test scripts to use `vitest run`
  - `vitest.config.js`: New configuration file for test environment
  - `tests/setup.js`: Converted Jest mocks to Vitest mocks using `vi.mock()`
  - All test files: Updated imports from `@jest/globals` to `vitest`
  - Mock functions: Changed `jest.fn()` to `vi.fn()` and `jest.spyOn()` to `vi.spyOn()`

#### Current Test Environment
- **Framework**: Vitest with native ES modules support
- **Environment**: Node.js test environment with mocked external dependencies
- **Coverage**: 59/102 tests passing (expected due to missing API implementations)
- **CI/CD**: GitHub Actions uses `npm test` which now runs Vitest

#### Test Results Breakdown
- ✅ **Unit Tests**: error handling, logging, restaurant controller (all passing)
- ✅ **ForecastAgent**: 24/24 tests passing (fully implemented)
- ⚠️ **InventoryAgent**: Tests fail due to missing method implementations in actual class
- ⚠️ **Integration Tests**: Fail due to missing API routes (expected during development)

### Deployment Strategy Overview

CostFX uses a **two-workflow deployment strategy** that separates application deployments from infrastructure changes:

1. **App Deployment** (`.github/workflows/app-deploy.yml`): Fast ECS-only updates for frontend/backend code changes
2. **Infrastructure Deployment** (`.github/workflows/infrastructure-deploy.yml`): Manual Terraform deployments for infrastructure changes

This separation provides:
- ⚡ **Fast app deployments** (~3-5 minutes vs ~15-20 minutes)
- 💰 **Cost optimization** by avoiding unnecessary Terraform runs
- 🔒 **Infrastructure stability** with controlled manual deployments
- 🎯 **Focused workflows** with clear separation of concerns

### Fresh Local Deployment Validation ✅ (September 29, 2025)

**Achievement**: Complete build and deployment verification after test architecture restoration

#### Build Process Validation
```bash
# Frontend Build (Vite)
npm run build:frontend
# ✅ Result: 695KB bundle built successfully in dist/

# Backend Build  
npm run build:backend
# ✅ Result: No build step required for Node.js (confirmed)

# Complete Project Build
npm run build
# ✅ Result: Both frontend and backend build processes completed
```

#### Docker Compose Deployment
```bash
# Clean Docker Environment
docker-compose down --remove-orphans && docker-compose up -d

# Services Status
docker-compose ps
# ✅ PostgreSQL 15: healthy on localhost:5432
# ✅ Redis 7-alpine: healthy on localhost:6379
```

#### Database Migration Resolution
**Issue Fixed**: Theoretical usage analysis migration referenced non-existent `users` table
```javascript
// Fixed: backend/migrations/1726790000008_create-theoretical-usage-analysis.js
assigned_to: {
  type: 'integer',
  notNull: false,
  // REMOVED: references: 'users(id)',
  comment: 'User assigned to investigate this variance (references future users table)'
}
```

**Migration Results**:
```bash
DATABASE_URL=postgresql://postgres:password@localhost:5432/restaurant_ai npm run migrate:up
# ✅ All 10 migrations applied successfully
# ✅ Database schema created: restaurants, suppliers, inventory_items, periods, snapshots, etc.
```

#### Database Seeding
```bash
DATABASE_URL=postgresql://postgres:password@localhost:5432/restaurant_ai npm run db:seed
# ✅ Demo Restaurant created (ID: 1)
# ✅ Sample data populated for development
```

#### Service Configuration Fix
**Issue Fixed**: Sequelize auto-sync conflicting with migration-based schema
```javascript
// Fixed: backend/src/config/database.js
// REMOVED: await sequelize.sync({ alter: true });
// ADDED: logger.info('📊 Database ready (development mode - using migrations)');
```

#### Service Startup Verification
```bash
# Backend Service
cd backend && DATABASE_URL=postgresql://postgres:password@localhost:5432/restaurant_ai REDIS_URL=redis://localhost:6379 npm run start
# ✅ Server running on port 3001
# ✅ Database connection established
# ✅ Redis connection established  

# Frontend Service
npm run dev:frontend
# ✅ Vite dev server on localhost:3000
# ✅ Proxy configured to backend (localhost:3001)
```

#### API Verification
```bash
# Test Backend API
curl -s http://localhost:3001/api/v1/restaurants
# ✅ Response: {"restaurants":[{"id":1,"name":"Demo Restaurant",...}],"total":1}

# Test Complete System
# ✅ Backend: http://localhost:3001 (Express API)
# ✅ Frontend: http://localhost:3000 (React/Vite)
# ✅ Database: PostgreSQL with all tables and seed data
# ✅ All 399/399 tests passing after deployment
```

#### Configuration Corrections Applied
1. **Frontend Proxy Fix**: Updated `frontend/vite.config.js` to proxy `/api` to `localhost:3001`
2. **Migration Dependency Fix**: Removed users table references in theoretical usage analysis
3. **Sequelize Sync Disable**: Prevented schema conflicts by using migration-only approach
4. **Port Resolution**: Backend on 3001, frontend on 3000 (no conflicts)

**Final Status**: ✅ **COMPLETE FRESH DEPLOYMENT SUCCESSFUL**
- All services healthy and operational
- Database schema current with all migrations
- API endpoints responding correctly
- Frontend serving and proxying properly
- Test suite maintains 100% pass rate (399/399)

### Application Deployment Workflow

**Triggers**: Automatically runs on push to `main`/`develop` when these paths change:
- `frontend/**`
- `backend/**` 
- `shared/**`
- `.env*` files
- `package.json`
- `deploy/docker/**`

**Process**:
1. **Smart Detection**: Only builds/deploys changed components (frontend or backend)
2. **Application Tests**: Runs Jest (backend) and Vitest (frontend) tests with PostgreSQL/Redis services
3. **Linting Checks**: ESLint validation (warnings allowed, errors block deployment)
4. **Docker Testing**: Tests container builds for changed components
5. **ECR Push**: Builds and pushes new container images with git SHA tags (only if tests pass)
6. **ECS Deployment**: Uses `aws-actions/amazon-ecs-deploy-task-definition` for fast updates
7. **Health Checks**: Validates deployment success with endpoint testing

**Test Requirements**:
- ✅ **Application tests MUST pass** - Jest (backend) and Vitest (frontend) with full database setup
- ⚠️ **Linting warnings allowed** - ESLint runs but warnings don't block deployment
- 🐳 **Docker builds must succeed** - Container builds tested before push

**Example Usage**:
```bash
# Automatic deployment when you push code changes
git add frontend/src/components/NewComponent.jsx
git commit -m "Add new dashboard component"
git push origin main  # Triggers app-deploy.yml automatically
```

### Infrastructure Deployment Workflow

**Triggers**: Manual only via GitHub Actions `workflow_dispatch`

**Use Cases**:
- Infrastructure changes (VPC, security groups, load balancers)
- Database schema migrations requiring downtime
- New AWS services or major configuration changes
- SSL certificate updates
- Terraform state management

**Process**:
1. **Manual Trigger**: Navigate to GitHub Actions → "CostFX Infrastructure Deploy" → "Run workflow"
2. **Environment Selection**: Choose dev/prod environment
3. **Application Tests**: Full test suite validation (Jest + Vitest with databases)
4. **Docker Testing**: Complete container build validation
5. **Full Terraform Run**: Plan and apply infrastructure changes
6. **Container Updates**: Optionally updates containers with latest images
7. **Complete Health Check**: Full system validation

**Test Requirements**:
- ✅ **All tests must pass** - Complete backend and frontend test suites
- ⚠️ **Linting warnings allowed** - Full codebase linting with warnings permitted
- 🐳 **All Docker builds validated** - Both frontend and backend containers tested

**Example Usage**:
```bash
# For infrastructure changes, use manual deployment
# 1. Make infrastructure changes in deploy/terraform/
# 2. Go to GitHub Actions → "CostFX Infrastructure Deploy (Manual)"
# 3. Click "Run workflow" → Select environment → Run
```

### Local Development Commands

```bash
# Run all tests (same as GitHub Actions)
npm test                    # Runs both backend and frontend tests
npm run test:backend       # Backend Jest tests with PostgreSQL
npm run test:frontend      # Frontend Vitest tests

# Run linting 
npm run lint               # Lint both backend and frontend
npm run lint:backend       # ESLint backend code
npm run lint:frontend      # ESLint frontend code

# Test containers locally (same as GitHub Actions)
docker build -f deploy/docker/Dockerfile.backend --target test .
docker build -f deploy/docker/Dockerfile.frontend --target test .

# Build production containers
docker build -f deploy/docker/Dockerfile.backend --target production .
docker build -f deploy/docker/Dockerfile.frontend --target production .

# Manual infrastructure deployment (emergency)
./deploy/scripts/deploy.sh
```

### Test Environment Requirements

**Backend Tests** (Jest):
- PostgreSQL database (uses `costfx_test` database)
- Redis instance for caching tests
- Environment variables: `NODE_ENV=test`, `DATABASE_URL`, `REDIS_URL`
- JWT and OpenAI test keys for agent testing

**Frontend Tests** (Vitest):
- Unit tests for React components
- Redux store testing
- API integration mocking
- UI component rendering validation

**Deployment Rules**:
- 🚫 **Tests failing = No deployment** - All tests must pass green
- ⚠️ **Linting warnings = Deployment continues** - Warnings logged but don't block
- 🔴 **Linting errors = No deployment** - Hard errors block deployment
- 🐳 **Docker build failure = No deployment** - Container builds must succeed

### AWS ECS Infrastructure

The application deploys to AWS using ECS Fargate with the following components:

#### Infrastructure Components
- **ECS Cluster**: `costfx-dev` with Fargate tasks for frontend and backend
- **ECS Services**: `costfx-dev-backend` and `costfx-dev-frontend`
- **Load Balancer**: ALB with `/api/*` → backend, `/*` → frontend routing
- **Databases**: RDS PostgreSQL and ElastiCache Redis (managed)
- **Container Registry**: ECR repositories `costfx-dev-backend` and `costfx-dev-frontend`
- **Networking**: VPC with public/private subnets and NAT gateways
- **Security**: Security groups and IAM roles with least privilege

#### Environment Variables

**Backend Production Environment**:
- `NODE_ENV=production`
- `PORT=5000`
- `DATABASE_URL` (from SSM Parameter Store)
- `REDIS_URL` (from SSM Parameter Store)
- `JWT_SECRET` (from SSM Parameter Store)
- `OPENAI_API_KEY` (from SSM Parameter Store)

**SSM Parameter Configuration**:
The application uses AWS Systems Manager (SSM) Parameter Store for secure configuration management:

```bash
# Current SSM Parameters (stored securely)
/costfx/dev/backend_api_url      # Backend API URL for frontend
/costfx/dev/database_url         # PostgreSQL connection string
/costfx/dev/jwt_secret          # JWT signing secret
/costfx/dev/openai_api_key      # OpenAI API key for AI agents
/costfx/dev/ssl_certificate_arn # SSL certificate ARN for HTTPS
```

**GitHub Actions Integration**:
The new app deployment workflow automatically updates SSM parameters and uses intelligent path filtering:

```yaml
# App deployment only triggers on relevant changes
on:
  push:
    paths:
      - 'frontend/**'      # Frontend code changes
      - 'backend/**'       # Backend code changes  
      - 'shared/**'        # Shared utilities
      - '.env*'            # Environment files
      - 'deploy/docker/**' # Docker configurations

# Smart component detection and building
- name: Check for app changes
  uses: dorny/paths-filter@v2
  id: changes
  with:
    filters: |
      backend:
        - 'backend/**'
        - 'shared/**'
        - 'deploy/docker/Dockerfile.backend'
      frontend:
        - 'frontend/**'
        - 'shared/**'
        - 'deploy/docker/Dockerfile.frontend'
```

**Infrastructure Deployment**:
Infrastructure changes use the manual workflow with Terraform:

```yaml
# Update application secrets in GitHub Actions
- name: Update application secrets
  run: |
    aws ssm put-parameter \
      --name '/costfx/${{ needs.setup.outputs.environment }}/jwt_secret' \
      --value '${{ secrets.JWT_SECRET }}' \
      --type SecureString \
      --overwrite \
      --region ${{ env.AWS_REGION }}
```

**Frontend Production Environment**:
- `VITE_API_URL=/api/v1` (relative path for ALB routing)
- `VITE_NODE_ENV=production`

**Production URLs**:
- **Frontend**: https://cost-fx.com/
- **Backend API**: https://cost-fx.com/api/v1/
- **Load Balancer**: costfx-dev-alb-1499165776.us-west-2.elb.amazonaws.com

### Monitoring and Observability

#### CloudWatch Monitoring
- **ALB Metrics**: Response time, error rates, target health
- **ECS Metrics**: CPU/memory utilization, task count
- **RDS Metrics**: Database connections, CPU utilization
- **Custom Metrics**: Agent performance, API response times

#### Alerts Configuration
```terraform
# Example CloudWatch alarm
resource "aws_cloudwatch_metric_alarm" "high_response_time" {
  alarm_name          = "costfx-high-response-time"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "TargetResponseTime"
  namespace           = "AWS/ApplicationELB"
  period              = "300"
  statistic           = "Average"
  threshold           = "1"
  alarm_description   = "This metric monitors ALB response time"
  alarm_actions       = [aws_sns_topic.alerts.arn]
}
```

#### Security Features
- **WAF Protection**: AWS WAF with OWASP Top 10 rules
- **SSL/TLS**: ACM certificate with automated renewal
- **VPC Security**: Private subnets for database and backend
- **IAM Roles**: Least privilege access for all services

---

## Troubleshooting

### Production Deployment Issues (September 19, 2025)

#### ForecastAgent "Network Error" in Production

**Symptoms**:
- ✅ Local development works perfectly
- ❌ Production shows "Failed to load demand forecast: Network Error"
- ❌ Browser console shows mixed content security errors

**Root Cause**: Frontend built with incorrect API URL causing HTTPS→HTTP requests

**Investigation Steps**:
```bash
# 1. Check ECS service health
aws ecs describe-services --cluster costfx-dev --services costfx-dev-frontend

# 2. Examine CloudWatch logs
aws logs get-log-events --log-group-name "/ecs/costfx-dev-frontend" \
  --log-stream-name "latest-stream"

# 3. Test API directly
curl https://www.cost-fx.com/api/v1/health

# 4. Check frontend build artifacts
docker run --rm frontend:latest grep -r "cost-fx.com" /usr/share/nginx/html/
```

**Solution**: Update GitHub Actions workflow
```yaml
# File: .github/workflows/app-deploy.yml
--build-arg VITE_API_URL="https://www.cost-fx.com/api/v1"  # Must include 'www'
```

#### Backend Container Failures (1486+ Failed Tasks)

**Symptoms**:
- ✅ Backend builds successfully
- ❌ ECS tasks exit with code 1 immediately
- ❌ High number of failed task attempts

**Investigation Steps**:
```bash
# 1. Check failed tasks
aws ecs describe-services --cluster costfx-dev --services costfx-dev-backend

# 2. Examine most recent failed task
aws ecs list-tasks --cluster costfx-dev --service-name costfx-dev-backend \
  --desired-status STOPPED --max-items 1

# 3. Check task definition environment variables
aws ecs describe-task-definition --task-definition costfx-dev-backend:latest \
  --query 'taskDefinition.containerDefinitions[0].{environment:environment,secrets:secrets}'

# 4. Review CloudWatch logs for exit reason
aws logs get-log-events --log-group-name "/ecs/costfx-dev-backend" \
  --log-stream-name "ecs/backend/<failed-task-id>"
```

**Root Cause**: Enhanced env-var validation requiring `POSTGRES_PASSWORD` even when `DATABASE_URL` provided

**Error Pattern**:
```
EnvVarError: env-var: "POSTGRES_PASSWORD" is a required variable, but it was not set
```

**Solution**: Enhanced database configuration flexibility
```javascript
// File: backend/src/config/database.js
const databaseUrl = env.get('DATABASE_URL').asUrlString();
const dbConfig = {
  password: env.get('POSTGRES_PASSWORD').asString(), // Made optional
  // ...
};

// Validation ensures either DATABASE_URL or individual credentials
if (!dbConfig.url && !dbConfig.password) {
  throw new Error('Either DATABASE_URL or POSTGRES_PASSWORD must be provided');
}
```

#### Mixed Content Security Policy Errors

**Symptoms**:
- ❌ Browser blocks API requests from HTTPS frontend
- ❌ DevTools shows "Mixed Content" warnings
- ✅ Direct API calls work correctly

**Root Cause**: Frontend trying to call HTTP endpoints from HTTPS page

**Investigation**:
```bash
# Check what URL is baked into frontend build
docker run --rm frontend:latest grep -r "elb.amazonaws.com" /usr/share/nginx/html/
```

**Solution**: Ensure frontend builds with HTTPS API URLs matching your domain

### Common Issues and Solutions

#### Development Environment

**Issue**: `npm run dev` fails to start
- **Cause**: Port conflicts or missing dependencies
- **Solution**: 
  ```bash
  # Check for port conflicts
  lsof -i :3000 -i :5000
  
  # Reinstall dependencies
  npm run clean && npm install
  ```

**Issue**: Database connection errors
- **Cause**: PostgreSQL not running or incorrect credentials
- **Solution**:
  ```bash
  # Start PostgreSQL (macOS)
  brew services start postgresql
  
  # Check connection
  psql -h localhost -U username -d costfx_dev
  ```

#### React Component Issues

**Issue**: ReferenceError for undefined function or state setter
- **Cause**: Function called without proper declaration (missing `useState`, `useCallback`, etc.)
- **Example**: `ReferenceError: setIsDisconnecting is not defined` in ConnectionStatus component
- **Solution**: 
  ```javascript
  // ❌ BAD: Calling undefined function
  const handleClick = () => {
    setIsLoading(true); // Error if useState not declared!
  };
  
  // ✅ GOOD: Properly declare state before using
  const [isLoading, setIsLoading] = useState(false);
  const handleClick = () => {
    setIsLoading(true);
  };
  
  // ✅ BETTER: Use existing Redux state instead of redundant local state
  const isLoading = useSelector(state => state.feature.loading);
  const handleClick = () => {
    dispatch(startLoading()); // Redux manages state
  };
  ```
- **Prevention**: 
  - Add component-level integration tests that exercise actual button clicks
  - Verify all function calls have corresponding declarations
  - Use ESLint with `no-undef` rule enabled
  - Prefer Redux for shared state over local `useState`
  - Run tests that mock actual user interactions, not just Redux actions

**Production Bug Fix Examples (October 2025):**

1. **Frontend - Disconnect Button Crash**
   - **Component**: `frontend/src/components/pos/square/ConnectionStatus.jsx`
   - **Bug**: `setIsDisconnecting is not defined` ReferenceError
   - **Root Cause**: Function called `setIsDisconnecting(true)` without `useState` declaration
   - **Fix**: Removed broken call; component already used Redux `loading.disconnect` state
   - **Tests Added**: 5 component tests in `ConnectionStatus.test.jsx` validating disconnect behavior
   - **Lesson**: Component-level tests catch issues that Redux unit tests miss

2. **Backend - Square Token Revocation**
   - **Component**: `backend/src/adapters/SquareAdapter.js`
   - **Bug**: `Argument for 'authorization' failed validation` from Square API
   - **Root Cause**: SDK `revokeToken()` not properly configured with Basic Auth
   - **Fix**: Replaced with direct axios HTTP call using Basic Auth header (base64 clientId:clientSecret)
   - **Lesson**: Test external API integrations; SDK abstractions can hide auth requirements

3. **Frontend - Data Contract Mismatch**
   - **Component**: `frontend/src/components/pos/square/ConnectionStatus.jsx`
   - **Bug**: Location names not displaying (empty bullets in list)
   - **Root Cause**: Component used `location.name` but backend sends `location.locationName`
   - **Fix**: Updated to `location.locationName || location.name` with fallback
   - **Lesson**: Validate frontend-backend data field naming consistency

#### Testing Issues

**Issue**: Tests failing with "describe is not defined" or ES module errors
- **Cause**: Missing Vitest imports or outdated Jest configuration
- **Solution**: 
  ```javascript
  // Ensure all test files have proper Vitest imports
  import { describe, test, expect, vi, beforeEach } from 'vitest';
  
  // Check vitest.config.js exists and is properly configured
  // Run: npm test (should use vitest run)
  ```

**Issue**: "Cannot find module" errors in tests
- **Cause**: Mock imports not properly configured for Vitest
- **Solution**:
  ```javascript
  // Use vi.mock() instead of jest.mock()
  vi.mock('../../src/models/SomeModel.js', () => ({
    default: {
      findAll: vi.fn()
    }
  }));
  ```

**Issue**: Tests pass locally but fail in CI/CD
- **Cause**: Database dependencies or environment differences
- **Solution**: 
  ```bash
  # Check that tests use mocks and don't require real database
  # Verify GitHub Actions uses: npm test (not npm run test:integration)
  # Check test scripts in package.json use vitest run
  ```

**Legacy Issue**: Jest tests failing with ES module errors (resolved September 2025)
- **Cause**: Jest experimental ES modules support was unstable
- **Solution**: ✅ **Migrated to Vitest** - Native ES modules support, better mock handling
- **Solution**: Ensure `jest.config.js` includes Babel transformation (see Technical Solutions)

**Issue**: Database tests failing
- **Cause**: Test database not properly reset between tests
- **Solution**: Use proper test setup:
  ```javascript
  // tests/setup.js
  beforeEach(async () => {
    await sequelize.sync({ force: true });
  });
  ```

#### Production Deployment

**Issue**: ECS tasks failing to start
- **Cause**: Environment variables not properly configured
- **Solution**: Check SSM Parameter Store values and ECS task definition

**Issue**: Database connection timeouts
- **Cause**: Security group configuration or connection pool limits
- **Solution**: 
  - Verify security group allows PostgreSQL traffic (port 5432)
  - Check RDS connection limits and adjust pool configuration

**Issue**: Frontend not loading
- **Cause**: ALB routing configuration or CORS issues
- **Solution**: 
  - Verify ALB listener rules for path-based routing
  - Check CORS configuration in backend

#### Performance Issues

**Issue**: Slow API responses
- **Cause**: Database queries not optimized or missing indexes
- **Solution**:
  ```sql
  -- Add indexes for common queries
  CREATE INDEX idx_inventory_items_restaurant_id ON inventory_items(restaurant_id);
  CREATE INDEX idx_transactions_item_id ON inventory_transactions(inventory_item_id);
  ```

**Issue**: High memory usage
- **Cause**: Memory leaks in agent processing
- **Solution**: 
  - Profile memory usage with Node.js built-in profiler
  - Implement proper cleanup in agent methods
  - Use Redis for caching to reduce memory pressure

### Debugging Tools

#### Backend Debugging
```javascript
// Enable debug logging
DEBUG=costfx:* npm run dev

// Use Node.js inspector
node --inspect src/index.js
```

#### Database Debugging
```sql
-- Enable query logging in PostgreSQL
ALTER SYSTEM SET log_statement = 'all';
SELECT pg_reload_conf();

-- Monitor slow queries
SELECT query, mean_time, calls 
FROM pg_stat_statements 
ORDER BY mean_time DESC 
LIMIT 10;
```

#### Container Debugging
```bash
# Check container logs
docker logs <container-id>

# Access running container
docker exec -it <container-id> /bin/sh

# Check ECS task logs
aws logs tail /costfx/backend --follow
```

### ECS Deployment Issues (September 24, 2025)

#### Slow ECS Deployments (18+ minutes)

**Problem**: ECS service deployments taking excessive time and timing out after 30 minutes with "Resource is not in the state servicesStable" error.

**Root Causes**:
1. **Aggressive Health Checks**: 30-second intervals with 5-second timeouts
2. **Container Startup Issues**: Invalid `PGSSLMODE` values causing application crashes
3. **Task Definition Changes**: New container images with stricter validation

**Investigation Commands**:
```bash
# Check deployment status
aws ecs describe-services --cluster costfx-dev --services costfx-dev-backend costfx-dev-frontend

# Check task definition differences
aws ecs describe-task-definition --task-definition costfx-dev-backend:38  # Working version
aws ecs describe-task-definition --task-definition costfx-dev-backend:39  # Failing version

# Check container logs
aws logs get-log-events --log-group-name /ecs/costfx-dev-backend \
  --log-stream-name $(aws logs describe-log-streams --log-group-name /ecs/costfx-dev-backend \
    --order-by LastEventTime --descending --max-items 1 --query 'logStreams[0].logStreamName' --output text)
```

**Solutions Applied**:
1. **Health Check Optimization**: Extended intervals (30s→60s), timeouts (5s→10s), retries (3→5)
2. **SSL Configuration Fix**: Changed `PGSSLMODE` from `"no-verify"` to `"require"`
3. **Application Validation**: Updated env-var configuration to accept valid PostgreSQL SSL modes

**Result**: Deployment time reduced from 18+ minutes to ~2 minutes ✅

#### Container Startup Failures

**Symptoms**:
```
EnvVarError: env-var: "PGSSLMODE" is not one of the allowed values. 
Allowed values: ['disable', 'allow', 'prefer', 'require', 'verify-ca', 'verify-full']
```

**Investigation**:
```bash
# Compare working vs failing task definitions
aws ecs describe-task-definition --task-definition costfx-dev-backend:38 \
  --query 'taskDefinition.containerDefinitions[0].environment[?name==`PGSSLMODE`]'

# Check stopped tasks for error details
aws ecs describe-tasks --cluster costfx-dev --tasks $(aws ecs list-tasks \
  --cluster costfx-dev --desired-status STOPPED --max-items 1 --query 'taskArns[0]' --output text)
```

**Solution**: Updated Terraform configuration with valid SSL mode:
```terraform
{
  name  = "PGSSLMODE"
  value = "require"  # Valid PostgreSQL SSL mode for AWS RDS
}
```

### Redis Development Environment Issues

#### Redis Connection Errors in Development

**Problem**: Local `npm run dev` showing Redis connection errors:
```
{"code":"ECONNREFUSED","level":"error","message":"Redis Client Error:","service":"restaurant-ai-backend"}
```

**Root Cause**: Redis client being created with default URL even when not needed for development.

**Investigation**:
```bash
# Check if Redis URL is set
echo "REDIS_URL: $REDIS_URL"
grep REDIS_URL .env

# Test current configuration
node -e "import('./backend/src/config/settings.js').then(m => console.log('Redis URL:', m.default.redisUrl))"
node -e "import('./backend/src/config/redis.js').then(m => console.log('Redis client:', m.redis ? 'created' : 'null'))"
```

**Solution**: Disabled Redis for development speed:
```bash
# Comment out Redis URL in .env
# REDIS_URL=redis://localhost:6379  # Disabled for development speed

# Verify bypass works
npm run dev  # Should show: "ℹ️ REDIS_URL not set; skipping Redis connection"
```

**Re-enabling Redis when needed**:
```bash
# Development
echo "REDIS_URL=redis://localhost:6379" >> .env
docker-compose up -d redis

# Production (uncomment in Terraform)
# deploy/terraform/database.tf - Redis resources
# deploy/terraform/ssm-parameters.tf - Redis URL parameter
terraform apply
```

#### Redis Container Management

**Commands**:
```bash
# Check Redis status
docker-compose ps redis
docker exec costfx-redis-1 redis-cli ping

# Start/stop Redis for development
docker-compose up -d redis    # Start
docker-compose stop redis     # Stop
docker-compose logs redis     # Check logs
```

---

## Change Log

### September 17, 2025 - Testing Framework Migration
**Major Update**: Migrated backend testing from Jest to Vitest for improved ES modules support

**Changes Made**:
- **Backend Testing Migration**:
  - Updated `package.json` test scripts from Jest to Vitest
  - Created `vitest.config.js` with proper ES modules configuration
  - Converted `tests/setup.js` from Jest mocks to Vitest mocks
  - Updated all test files: imports, mock functions, and spy methods
  - Result: 59/102 tests now passing (vs 0% with failing Jest setup)

- **GitHub Actions Optimization**:
  - Confirmed dual-workflow strategy working correctly
  - App deployment uses fast Vitest testing (no database required)
  - Infrastructure deployment uses comprehensive testing (database included)

- **Documentation Updates**:
  - Updated technical documentation with current test status
  - Added troubleshooting section for testing issues
  - Documented the Jest→Vitest migration process and rationale

**Technical Rationale**:
- Jest's experimental ES modules support was unstable in CI/CD
- Vitest provides native ES modules support without experimental flags
- Better mock handling and faster test execution
- Maintains same test coverage while improving reliability

**Current Status**:
- ✅ CI/CD pipeline functional with Vitest
- ✅ Mock-based testing eliminates database dependencies in app deployment
- ⚠️ Some tests need implementation alignment (expected during development)
- 🎯 Ready for continued development with stable testing foundation

## AWS Deployment Troubleshooting

### SSM Parameter Access Issues

**Problem**: GitHub Actions deployment fails with SSM access denied error:
```
An error occurred (AccessDeniedException) when calling the GetParameter operation: 
User: arn:aws:sts::568530517605:assumed-role/GitHubActionsRole-CostFX/GitHubActions 
is not authorized to perform: ssm:GetParameter
```

**Solution**: Update IAM policy for GitHubActionsRole-CostFX to include SSM permissions:
```bash
# Add to CostFX-Deployment-Policy
{
  "Sid": "SSMParameterAccess",
  "Effect": "Allow",
  "Action": ["ssm:GetParameter", "ssm:GetParameters"],
  "Resource": ["arn:aws:ssm:us-west-2:568530517605:parameter/costfx/dev/*"]
}
```

**Applied Fix (Sep 19, 2025)**:
```bash
aws iam create-policy-version \
  --policy-arn arn:aws:iam::568530517605:policy/CostFX-Deployment-Policy \
  --policy-document file://updated-policy.json \
  --set-as-default
```

### Database Migration Connection Failures

**Problem**: Migrations fail with localhost connection errors during deployment.

**Root Cause**: Wrong SSM parameter path in GitHub Actions workflow
- ❌ Used: `/costfx/dev/database/url` 
- ✅ Correct: `/costfx/dev/database_url`

**Solution**: Update `.github/workflows/app-deploy.yml`:
```yaml
export DATABASE_URL=$(aws ssm get-parameter --name "/costfx/dev/database_url" --with-decryption --query 'Parameter.Value' --output text)
```

**Verification Commands**:
```bash
# List available parameters
aws ssm get-parameters-by-path --path "/costfx/dev" --query 'Parameters[].Name'

# Test database URL retrieval
aws ssm get-parameter --name "/costfx/dev/database_url" --with-decryption --query 'Parameter.Value' --output text
```

---

*This documentation follows the Diátaxis framework for systematic technical documentation, organizing content by user needs: tutorials for learning, how-to guides for solving problems, reference for information, and explanation for understanding.*
